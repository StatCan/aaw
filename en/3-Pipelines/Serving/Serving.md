# Model Serving with Seldon Core and KFServing

<!-- prettier-ignore -->
!!! warning "⚒ This page is under construction ⚒" 
    The person writing this entry does not know enough about 
    this feature to write about it, but you can ask on our Slack channel.

## Serverless with KNative

Kubernetes and [KNative](https://knative.dev/) let your services scale up and
down on demand. This lets you create APIs to serve Machine Learning models,
without the need to manage load balancing or scale-up. The platform can handle
all of your scaling for you, so that you can focus on the program logic.

<!-- prettier-ignore -->
!!! warning "⚒ This page is under construction ⚒" 
    The person writing this entry does not know enough about this 
    feature to write about it, but you can ask on our Slack channel.
