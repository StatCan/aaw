{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"D\u00e9marrer sur l'espace de travail d'analyse avanc\u00e9e","text":"<p>Le portail de l'espace de travail d'analyse avanc\u00e9e est un excellent endroit o\u00f9 explorer les ressources dont il sera question ici, et y acc\u00e9der.</p>"},{"location":"#que-cherchez-vous","title":"Que cherchez-vous ?","text":""},{"location":"#demarrer-avec-aaw","title":"D\u00e9marrer avec AAW","text":"<p> Tout commence avec Kubeflow! Commencez par le configurer.</p> <p> Vous allez avoir des questions. Rejoignez notre Canal Slack pour que nous puissions vous donner des r\u00e9ponses!</p> <p></p> <p>Cliquez sur le lien, puis choisissez \"Cr\u00e9er un compte\" dans le coin en haut \u00e0 droite.</p> <p></p> <p>Utilisez votre adresse \u00e9lectronique @statcan.gc.ca pour que votre demande soit automatiquement approuv\u00e9e.</p>"},{"location":"#experiences","title":"Exp\u00e9riences","text":""},{"location":"#traiter-les-donnees-en-utilisant-les-serveurs-bloc-notes","title":"Traiter les donn\u00e9es en utilisant les serveurs bloc-notes","text":"<p>Dans Kubeflow, les Serveurs Bloc-Notes vous permet d'obtenir un environnement de calcul interactif pour traiter les donn\u00e9es. Tous les serveurs bloc-notes ont acc\u00e8s \u00e0 un maximum de 15CPU/48GB RAM et \u00e0 un stockage \u00e0 l'\u00e9chelle de GB/TB, mais ont une interface utilisateur diff\u00e9rente selon la version que vous choisissez.</p> <ul> <li>Python, Julia et R via un Bloc-notes Jupyter.</li> <li>R via RStudio</li> </ul>"},{"location":"#bloc-notes-jupyter-pour-python-julia-ou-r","title":"Bloc-notes Jupyter pour <code>Python</code>, <code>Julia</code>, ou <code>R</code>","text":"<p>Utilisez un Bloc-notes Jupyter pour cr\u00e9er et partager des documents interactifs qui contiennent un m\u00e9lange de code en direct, de visualisations et de texte. Ceux-ci peuvent \u00eatre \u00e9crits en <code>Python</code>,<code>Julia</code> ou <code>R</code>.</p> <p></p> <p>Pour lancer un serveur bloc-notes avec une interface Jupyter, choisissez l'une des images <code>jupyterlab</code> lors de la cr\u00e9ation de votre serveur bloc-notes. L'image <code>jupyterlab</code> est \u00e9galement pr\u00e9charg\u00e9e avec VS Code dans le navigateur si vous pr\u00e9f\u00e9rez une exp\u00e9rience IDE compl\u00e8te.</p>"},{"location":"#rstudio-pour-r-et-shiny","title":"RStudio pour <code>R</code> et <code>Shiny</code>","text":"<p>RStudio vous offre un environnement de d\u00e9veloppement int\u00e9gr\u00e9 sp\u00e9cifiquement pour R. Si vous codez en R, c'est typiquement le serveur bloc-notes \u00e0 utiliser. Utilisez l'image <code>rstudio</code> pour obtenir un environnement RStudio.</p> <p></p>"},{"location":"#executer-un-bureau-virtuel","title":"Ex\u00e9cuter un bureau virtuel","text":"<p>Pour une exp\u00e9rience de bureau Ubuntu compl\u00e8te, utilisez l'un de nos serveurs bloc-notes <code>remote-desktop</code>.Vous pouvez ex\u00e9cuter un bureau Ubuntu complet, avec des applications typiques, directement dans votre navigateur, en utilisant Espace de travail ML</p>"},{"location":"#publication","title":"Publication","text":""},{"location":"#construire-et-publier-un-tableau-de-bord-interactif","title":"Construire et publier un tableau de bord interactif","text":"<p> Utilisez R-Shiny pour cr\u00e9er des applications web interactives directement \u00e0 partir de R. Vous pouvez d\u00e9ployer votre tableau de bord R-Shiny en soumettant une requ\u00eate de tirage \u00e0 notre d\u00e9p\u00f4t GitHub R-Dashboards. </p> <p>Dash est un outil de visualisation de donn\u00e9es qui vous permet de construire une interface graphique interactive autour de votre code d'analyse de donn\u00e9es.</p>"},{"location":"#explorer-vos-donnees","title":"Explorer vos donn\u00e9es","text":"<p> Utilisez Datasette , une API JSON instantan\u00e9e pour vos bases de donn\u00e9es SQLite. Ex\u00e9cutez des requ\u00eates SQL d'une mani\u00e8re plus interactive !</p>"},{"location":"#pipelines","title":"Pipelines","text":""},{"location":"#creer-et-planifier-des-pipelines-de-donneesanalyse","title":"Cr\u00e9er et planifier des pipelines de donn\u00e9es/analyse","text":"<p> Kubeflow Pipelines vous permet de mettre en place des pipelines. Chaque pipelines encapsulent des flux de production analytiques et peuvent \u00eatre mis en commun, r\u00e9utilis\u00e9s et programm\u00e9s. </p> <p></p>"},{"location":"#integration-avec-les-offres-de-plateforme-en-tant-que-service-paas","title":"Int\u00e9gration avec les offres de plateforme en tant que service (PaaS)","text":"<p>Nous pouvons nous int\u00e9grer \u00e0 de nombreuses offres de Plateforme en tant que Service (PaaS), telles que Databricks ou AzureML.</p>"},{"location":"#collaboration","title":"Collaboration","text":""},{"location":"#partage-du-code","title":"Partage du code","text":"<p> Utilise GitHub ou GitLab pour partager votre code avec les membres de votre \u00e9quipe, ou demander pour un espace de travail partag\u00e9 .</p> <p>Demander de l'aide pour la production</p> <p>Le personnel de soutien de l'espace de travail d'analyse avanc\u00e9e est heureux de vous aider pour les cas d'utilisation orient\u00e9s vers la production, et nous pouvons probablement vous faire gagner beaucoup de temps. N'h\u00e9sitez pas \u00e0 nous demander pour de l'aide!</p>"},{"location":"#comment-obtenir-des-donnees-comment-envoyer-des-donnees","title":"Comment obtenir des donn\u00e9es? Comment envoyer des donn\u00e9es?","text":"<ul> <li>Chaque espace de travail peut \u00eatre \u00e9quip\u00e9 de son propre stockage.</li> </ul> <ul> <li>Il existe \u00e9galement des compartiments de stockage pour la publication   d'ensembles de donn\u00e9es, pour usage interne ou diffusion plus large.</li> </ul> <p>Nous donnerons un aper\u00e7u des technologies ici. Des renseignements plus pr\u00e9cis sur chacune d'entre elles seront fournis dans les sections suivantes.</p> <p>Parcourir quelques ensembles de donn\u00e9es</p> <p>Parcourez quelques ensembles de donn\u00e9es ici. Ces ensembles de donn\u00e9es ont \u00e9t\u00e9 con\u00e7us pour stocker des donn\u00e9es largement partag\u00e9es. Il peut s'agir de donn\u00e9es qui ont \u00e9t\u00e9 introduites, ou de donn\u00e9es qui seront diffus\u00e9es sous forme de produit. Comme toujours, veillez \u00e0 ce qu'il ne s'agisse pas de donn\u00e9es de nature d\u00e9licate.</p>"},{"location":"Aide/","title":"Vous avez des questions ou des commentaires?","text":"<p>Joignez-vous \u00e0 nous sur le canal Slack de l'espace de travail en analytique avanc\u00e9e! Vous trouverez de nombreux utilisateurs de la plateforme qui pourront peut-\u00eatre r\u00e9pondre \u00e0 vos questions. Quelques ing\u00e9nieurs sont aussi habituellement pr\u00e9sents. Vous pouvez poser des questions et soumettre vos commentaires.</p> <ul> <li>Slack (fr)</li> </ul> <p>Nous publierons \u00e9galement des avis de mise \u00e0 jour et d'interruption sur le canal Slack.</p>"},{"location":"Aide/#videos-tutoriels","title":"Vid\u00e9os tutoriels","text":"<p>Une fois que vous vous \u00eates joint \u00e0 notre communaut\u00e9 Slack, prenez le temps de fureter nos vid\u00e9os tutoriels!</p> <ul> <li>Vid\u00e9os tutoriels officiels</li> <li>D\u00e9mo et contenue provenus de la communaut\u00e9 de l'EAA</li> </ul>"},{"location":"Aide/#github","title":"GitHub","text":"<p>Vous voulez en savoir plus \u00e0 propos de notre plateforme? Trouvez tous les d\u00e9tailles sur notre page GitHub!</p> <ul> <li>Page GitHub de l'Espace d'analyse avanc\u00e9e</li> </ul>"},{"location":"Collaboration/","title":"Collaboration en mati\u00e8re d'espace de travail en analytique avanc\u00e9e","text":"<p>Il existe de nombreuses fa\u00e7ons de collaborer sur la plateforme, et ce qui vous convient le mieux d\u00e9pend des \u00e9l\u00e9ments que vous partagez et du nombre de personnes avec qui vous souhaitez partager des \u00e9l\u00e9ments. Nous pouvons r\u00e9partir les \u00e9l\u00e9ments partageables en donn\u00e9es et en code. Nous pouvons aussi r\u00e9partir l'ensemble des groupes avec lesquels vous partagez des \u00e9l\u00e9ments en priv\u00e9, \u00e9quipe et StatCan. Cela conduit au tableau d'options suivant :</p> Priv\u00e9 \u00c9quipe StatCan Code GitLab/GitHub ou dossier personnel GitLab/GitHub ou dossier d'\u00e9quipe GitLab/GitHub Donn\u00e9es Dossier ou compartiment personnel Dossier ou compartiment d'\u00e9quipe Compartiment partag\u00e9 Quelle est la diff\u00e9rence entre un compartiment et un dossier? <p>Les compartiments s'apparentent au stockage r\u00e9seau. Voir la section sur le stockage pour obtenir des pr\u00e9cisions suppl\u00e9mentaires sur les diff\u00e9rences entre ces deux concepts.</p> <p>Les acc\u00e8s priv\u00e9 et \u00e9quipe sont configur\u00e9s au moyen des espaces de nommage. Nous commen\u00e7ons donc par parler de Kubeflow et des espaces de nommage Kubeflow.</p> <p>Ensuite, les donn\u00e9es et le code sont mieux pris en charge au moyen d'outils l\u00e9g\u00e8rement diff\u00e9rents. C'est pourquoi nous allons les aborder en deux temps. Pour les donn\u00e9es, nous parlons de compartiments et MinIO. Pour le code, nous parlons de Git, GitLab et GitHub.</p> <p>C'est sur quoi repose la structure de cette page :</p> <p>\u2013 Collaboration en \u00e9quipe (applicable au code et aux donn\u00e9es) \u2013 Partage du code \u2013 Partage des donn\u00e9es</p>"},{"location":"Collaboration/#collaboration-en-equipe","title":"Collaboration en \u00e9quipe","text":""},{"location":"Collaboration/#que-fait-kubeflow","title":"Que fait Kubeflow?","text":"<p>Kubeflow ex\u00e9cute vos espaces de travail. Vous pouvez avoir des serveurs de blocs-notes (appel\u00e9s serveurs Jupyter) et vous pouvez y cr\u00e9er des analyses en R et en Python en utilisant des \u00e9l\u00e9ments visuels interactifs. Vous pouvez enregistrer, t\u00e9l\u00e9verser et t\u00e9l\u00e9charger des donn\u00e9es. Votre \u00e9quipe peut travailler \u00e0 vos c\u00f4t\u00e9s.</p>"},{"location":"Collaboration/#demande-dun-espace-de-nommage","title":"Demande d'un espace de nommage","text":"<p>Par d\u00e9faut, chaque personne obtient son propre espace de nommage, <code>pr\u00e9nom-nom</code>. Si vous souhaitez cr\u00e9er un espace de nommage pour une \u00e9quipe, pr\u00e9sentez la demande dans le portail : Cliquez sur le \u22ee de la section Kubeflow du portail.</p> <p>L'espace de nommage ne doit comprendre aucun caract\u00e8re sp\u00e9cial autre que le trait d'union.</p> <p>Le nom doit seulement comprendre des lettres minuscules (de \u00ab a \u00bb \u00e0 \u00ab z \u00bb) et des traits d'union. Sinon, il sera impossible de cr\u00e9er l'espace de nommage.</p> <p>Vous recevrez un avis par courriel vous indiquant que l'espace de nommage est cr\u00e9\u00e9. Une fois que l'espace de nommage partag\u00e9 est cr\u00e9\u00e9, vous pouvez y acc\u00e9der comme tous les autres espaces de nommage dont vous disposez par l'entremise de l'interface utilisateur Kubeflow, comme il est indiqu\u00e9 ci-apr\u00e8s. Vous pourrez ensuite g\u00e9rer la liste des collaborateurs sous l'onglet de gestion des contributeurs de Kubeflow, o\u00f9 vous pourrez ajouter vos coll\u00e8gues \u00e0 l'espace de nommage partag\u00e9.</p> <p></p> <p>Pour changer d'espace de nommage, allez en haut de votre fen\u00eatre, juste \u00e0 droite du logo de Kubeflow.</p> <p></p>"},{"location":"Collaboration/#code-partage","title":"Code partag\u00e9","text":"<p>Les \u00e9quipes ont deux options (mais vous pouvez combiner les deux) :</p>"},{"location":"Collaboration/#partager-un-espace-de-travail-dans-kubeflow","title":"Partager un espace de travail dans Kubeflow","text":"<p>Le partage dans Kubeflow pr\u00e9sente l'avantage suivant : il est \u00e0 structure libre et il fonctionne mieux pour les fichiers <code>.ipynb</code> (blocs-notes Jupyter). Cette m\u00e9thode vous permet \u00e9galement de partager un environnement de calcul, de sorte que vous pouvez partager des ressources tr\u00e8s facilement. Lorsque vous partagez un espace de travail, vous partagez :</p> <p>\u2013 un compartiment priv\u00e9 et partag\u00e9 (<code>/team-name</code> et <code>/shared/team-name</code>); \u2013 tous les serveurs de blocs-notes dans l'espace de nommage Kubeflow.</p>"},{"location":"Collaboration/#partager-avec-git-au-moyen-de-gitlab-ou-de-github","title":"Partager avec Git, au moyen de GitLab ou de GitHub","text":"<p>Le partage au moyen de Git pr\u00e9sente l'avantage suivant : il permet de travailler avec des utilisateurs de tous les espaces de nommage. De plus, le fait de conserver le code dans Git est un excellent moyen de g\u00e9rer les grands projets de logiciels.</p> <p>N'oubliez pas d'obtenir une licence d'utilisation!</p> <p>Si votre code est public, suivez les directives de l'\u00e9quipe de l'innovation et utilisez une licence appropri\u00e9e si vous r\u00e9alisez des t\u00e2ches pour le compte de Statistique Canada.</p>"},{"location":"Collaboration/#recommandation-combinez-les-deux","title":"Recommandation : combinez les deux.","text":"<p>Il est sage de toujours utiliser Git. L'utilisation de Git de concert avec des espaces de travail partag\u00e9s est un bon moyen de combiner le partage ponctuel (par l'entremise de fichiers) tout en assurant l'organisation et le suivi de votre code.</p>"},{"location":"Collaboration/#stockage-partage","title":"Stockage partag\u00e9","text":""},{"location":"Collaboration/#partage-avec-votre-equipe","title":"Partage avec votre \u00e9quipe","text":"<p>Une fois que vous avez un espace de nommage partag\u00e9, deux m\u00e9thodes de stockage partag\u00e9 s'offrent \u00e0 vous :</p> Option de stockage Avantages Serveurs/espaces de travail Jupyter partag\u00e9s Mieux adapt\u00e9s aux petits fichiers, aux blocs-notes et aux petites exp\u00e9riences. Compartiments partag\u00e9s (voir Stockage) Mieux adapt\u00e9s \u00e0 une utilisation dans les pipelines et les interfaces API et aux fichiers volumineux. <p>Pour en savoir plus sur la technologie sous-jacente, consultez la section sur le stockage.</p>"},{"location":"Collaboration/#partage-avec-statcan","title":"Partage avec StatCan","text":"<p>En plus des compartiments priv\u00e9s et des compartiments priv\u00e9s partag\u00e9s en \u00e9quipe, vous pouvez \u00e9galement placer vos fichiers dans un espace de stockage partag\u00e9. Toutes les options de stockage en compartiments (<code>minimal</code>, <code>sup\u00e9rieur</code>, <code>\u00e9l\u00e9phantesque</code>) offrent un compartiment priv\u00e9 et un dossier \u00e0 l'int\u00e9rieur du compartiment <code>partag\u00e9</code>. Par exemple, consultez le lien ci-dessous :</p> <ul> <li><code>shared/blair-drummond/</code></li> </ul> <p>Tous les utilisateurs connect\u00e9s peuvent visualiser et consulter ces fichiers librement.</p>"},{"location":"Collaboration/#partage-avec-le-monde","title":"Partage avec le monde","text":"<p>Renseignez-vous \u00e0 ce sujet sur notre canal Slack. Il existe de nombreuses m\u00e9thodes de partage avec le monde du point de vue informatique. Cependant, comme il est important de respecter les processus appropri\u00e9s, on n'utilise pas le libre-service, comme dans les autres cas. Cela dit, c'est possible.</p>"},{"location":"message-de-bienvenue/","title":"Message de bienvenue","text":""},{"location":"message-de-bienvenue/#bienvenue-a-lespace-danalyse-avance-eaa","title":"\ud83e\uddd9\ud83d\udd2e Bienvenue \u00e0 l\u2019Espace d'analyse avanc\u00e9 (EAA)","text":"<p>Veuillez trouver ci-dessous des informations, des vid\u00e9os et des liens suppl\u00e9mentaires pour mieux comprendre comment d\u00e9marrer avec l\u2019Espace d'analyse avanc\u00e9 (EAA).</p> <p>L\u2019Espace d'analyse avanc\u00e9 (EAA) est notre plateforme open source pour la science des donn\u00e9es et l'apprentissage automatique (ML) destin\u00e9e aux praticiens avanc\u00e9s, qui peuvent ainsi accomplir leur travail dans un environnement sans restriction, con\u00e7u par des scientifiques des donn\u00e9es pour des scientifiques des donn\u00e9es. Avec EAA, vous pouvez personnaliser vos d\u00e9ploiements d'ordinateurs portables pour r\u00e9pondre \u00e0 vos besoins en mati\u00e8re de science des donn\u00e9es. Nous disposons \u00e9galement d'un petit nombre d'images r\u00e9alis\u00e9es par notre \u00e9quipe experte en science des donn\u00e9es.</p> <p>EAA est bas\u00e9 sur le projet Kubeflow qui est une solution compl\u00e8te open source pour le d\u00e9ploiement et la gestion de flux de travail ML de bout en bout. Kubeflow est con\u00e7u pour rendre les d\u00e9ploiements de flux de travail ML sur Kubernetes simples, portables et \u00e9volutifs.</p> <p>\ud83d\udd14 Important! Les utilisateurs externes \u00e0 Statistique Canada devront disposer d'un compte cloud dont l'acc\u00e8s est accord\u00e9 par le commanditaire de l'entreprise.</p> <p>\ud83d\udd14 Important! Les utilisateurs internes \u00e0 Statistique Canada peuvent commencer tout de suite sans proc\u00e9dure d'inscription suppl\u00e9mentaire, il suffit de se rendre \u00e0 l'adresse https://kubeflow.aaw.cloud.statcan.ca/.</p>"},{"location":"message-de-bienvenue/#liens-utiles","title":"\ud83d\udd17 Liens utiles","text":""},{"location":"message-de-bienvenue/#services-eaa","title":"\ud83d\udece\ufe0f Services EAA","text":"<ul> <li>\ud83c\udf00 Page d'accueil du portail EEA<ul> <li>Interne seulement https://www.statcan.gc.ca/data-analytics-service/aaw</li> <li>Interne/externe https://analytics-platform.statcan.gc.ca/covid19</li> </ul> </li> </ul> <ul> <li>\ud83e\udd16 Tableau de bord Kubeflow<ul> <li>https://kubeflow.aaw.cloud.statcan.ca/</li> </ul> </li> </ul>"},{"location":"message-de-bienvenue/#aide","title":"\ud83d\udca1 Aide","text":"<ul> <li>\ud83d\udcd7 Documentation du portail EAA<ul> <li>https://statcan.github.io/daaas/</li> </ul> </li> <li>\ud83d\udcd8 Documentation sur Kubeflow<ul> <li>https://www.kubeflow.org/docs/</li> </ul> </li> <li>\ud83e\udd1d Canal de support Slack<ul> <li>https://statcan-aaw.slack.com</li> </ul> </li> </ul>"},{"location":"message-de-bienvenue/#mise-en-route","title":"\ud83e\udded Mise en route","text":"<p>Afin d'acc\u00e9der aux services de l'EAA, vous devrez:</p> <ol> <li>Vous connecter \u00e0 Kubeflow avec votre compte cloud invit\u00e9 StatCan. Vous serez invit\u00e9 \u00e0 authentifier le compte.</li> <li>S\u00e9lectionnez Notebook Servers.</li> <li>Cliquez sur le bouton \" \u2795 Nouveau serveur \".</li> </ol>"},{"location":"message-de-bienvenue/#outils-offerts","title":"\ud83e\uddf0 Outils offerts","text":"<p>AAW est une plateforme flexible pour l'analyse de donn\u00e9es et l'apprentissage automatique, avec:</p> <ul> <li>\ud83d\udcdc Langues<ul> <li>\ud83d\udc0d Python</li> <li>\ud83d\udcc8 R</li> <li>\ud83d\udc69\ud83d\udd2c Julia</li> <li>SAS (Prochainement!)</li> </ul> </li> <li>\ud83e\uddee Environnements de d\u00e9veloppement<ul> <li>VS Code</li> <li>R Studio</li> <li>Jupyter Notebooks</li> </ul> </li> <li>\ud83d\udc27 Bureaux virtuels Linux pour des outils suppl\u00e9mentaires (\ud83e\uddeb OpenM++, \ud83c\udf0f QGIS, etc.)</li> </ul>"},{"location":"message-de-bienvenue/#demonstrations","title":"\ud83d\udc31 D\u00e9monstrations","text":"<p>Si vous souhaitez une session d'embarquement/d\u00e9mo rapide ou si vous avez besoin d'aide ou avez des questions, n'h\u00e9sitez pas \u00e0 nous contacter via notre canal de support \ud83e\udd1d Slack.</p>"},{"location":"message-de-bienvenue/#faq","title":"FAQ","text":"<ul> <li>\ud83d\udea7 Bient\u00f4t disponible !</li> </ul> <p>Merci !</p>"},{"location":"1-Experiences/Bureau-virtuel/","title":"Bureau virtuel","text":""},{"location":"1-Experiences/Bureau-virtuel/#quest-ce-quun-bureau-virtuel","title":"Qu'est-ce qu'un Bureau virtuel?","text":"<p>Le bureau \u00e0 distance offre une exp\u00e9rience de bureau Ubuntu avec une interface graphique dans le navigateur, ainsi qu'un acc\u00e8s rapide aux outils de support. Le syst\u00e8me d'exploitation est Ubuntu 18.04 avec l'environnement de bureau XFCE.</p>"},{"location":"1-Experiences/Bureau-virtuel/#versions","title":"Versions","text":"<p>Deux versions du Bureau virtuel sont disponibles. R comprend R et RStudio. Geomatics \u00e9tend R avec QGIS et diverses biblioth\u00e8ques de support. Vous pouvez personnaliser votre espace de travail en fonction de vos besoins et de vos pr\u00e9f\u00e9rences.</p>"},{"location":"1-Experiences/Bureau-virtuel/#personnalisation","title":"Personnalisation","text":"<p>pip, conda, npm et yarn sont disponibles pour installer divers paquets.</p>"},{"location":"1-Experiences/Bureau-virtuel/#acceder-au-bureau-virtuel","title":"Acc\u00e9der au Bureau virtuel","text":"<p>Pour lancer le Bureau virtuel ou l'un de ses outils de support, cr\u00e9ez un serveur bloc-notes dans Kubeflow et s\u00e9lectionnez l'une des versions disponibles dans la liste des images. Ensuite, cliquez sur <code>Connecter</code> pour acc\u00e9der au Bureau virtuel.</p> <p>Un Bureau virtuel vous permet d'acc\u00e9der \u00e0 l'interface graphique du bureau via une session noVNC. Cliquez sur le '&lt;' sur le c\u00f4t\u00e9 gauche de l'\u00e9cran pour ouvrir un panneau avec des options telles qu'un plein \u00e9cran et l'acc\u00e8s au presse-papiers.</p> <p></p>"},{"location":"1-Experiences/Bureau-virtuel/#outils-dans-le-navigateur","title":"Outils dans le Navigateur","text":""},{"location":"1-Experiences/Bureau-virtuel/#vs-code","title":"VS Code","text":"<p>Visual Studio Code est un \u00e9diteur de code source l\u00e9ger mais puissant. Il est livr\u00e9 avec un support int\u00e9gr\u00e9 pour JavaScript, TypeScript et Node.js et poss\u00e8de un riche \u00e9cosyst\u00e8me d'extensions pour plusieurs langages (tels que C++, C#, Java, Python, PHP, Go).</p> <p></p>"},{"location":"1-Experiences/Bureau-virtuel/#notes-de-bas-de-page","title":"Notes de bas de page","text":"<p>Bureau virtuel est bas\u00e9 sur ml-tooling/ml-workspace.</p>"},{"location":"1-Experiences/Jupyter/","title":"Aper\u00e7u","text":""},{"location":"1-Experiences/Jupyter/#jupyter-experience-conviviale-de-r-et-python","title":"Jupyter: Exp\u00e9rience conviviale de R et Python","text":"<p>Jupyter vous permet d'obtenir des bloc-notes pour \u00e9crire votre code et faire des visualisations. Vous pouvez rapidement it\u00e9rer, visualiser et partager vos analyses. Puisque Jupyter est ex\u00e9cut\u00e9 sur un serveur (que vous avez mis en place dans la derni\u00e8re section), il vous permet d'effectuer de tr\u00e8s grandes analyses sur un mat\u00e9riel centralis\u00e9! Ajoutez autant de puissance qu'il vous faut! Et puisque c'est dans le nuage, vous pouvez aussi le partager avec vos coll\u00e8gues.</p>"},{"location":"1-Experiences/Jupyter/#explorez-vos-donnees","title":"Explorez vos donn\u00e9es","text":"<p>Jupyter offre un certain nombre de fonctionnalit\u00e9s (et nous pouvons en ajouter d'autres)</p> <ul> <li>\u00c9l\u00e9ments visuels int\u00e9gr\u00e9s dans votre bloc-notes</li> <li>Volume de donn\u00e9es pour le stockage de vos donn\u00e9es</li> <li>Possibilit\u00e9 de partager votre espace de travail avec vos coll\u00e8gues</li> </ul> <p></p>"},{"location":"1-Experiences/Jupyter/#environnement-de-developpement-dans-le-navigateur","title":"Environnement de d\u00e9veloppement dans le navigateur","text":"<p>Cr\u00e9ez pour explorer, et aussi pour \u00e9crire du code</p> <ul> <li>Linting et d\u00e9bogage</li> <li>Int\u00e9gration Git</li> <li>Terminal int\u00e9gr\u00e9</li> <li>Th\u00e8me clair/fonc\u00e9 (changer les param\u00e8tres en haut)</li> </ul> <p></p> <p>Plus de renseignements sur Jupyter ici</p>"},{"location":"1-Experiences/Jupyter/#installation","title":"Installation","text":""},{"location":"1-Experiences/Jupyter/#commencez-par-les-exemples","title":"Commencez par les exemples","text":"<p>Lorsque vous avez d\u00e9marr\u00e9 votre serveur, il a \u00e9t\u00e9 charg\u00e9 de mod\u00e8les de bloc-notes. Parmi les bons blocs-notes pour commencer, il y a <code>R/01-R-Notebook-Demo.ipynb</code> et ceux dans <code>scikitlearn</code>. Les bloc-notes <code>pytorch</code> et <code>tensorflow</code> sont excellents si vous connaissez l'apprentissage automatique. <code>mapreduce-pipeline</code> et <code>ai-pipeline</code> sont plus avanc\u00e9s.</p> Certains bloc-notes ne fonctionnent que dans certaines versions de serveur <p>Par exemple, <code>gdal</code> ne fonctionne que dans l'image g\u00e9omatique. Donc, si vous utilisez une autre image, un bloc-notes utilisant <code>gdal</code> pourrait ne pas fonctionner.</p>"},{"location":"1-Experiences/Jupyter/#ajout-de-logiciels","title":"Ajout de logiciels","text":"<p>Vous n'avez pas <code>sudo</code> dans Jupyter, mais vous pouvez utiliser</p> <pre><code>conda install --use-local your_package_name\n</code></pre> <p>ou</p> <pre><code>pip install --user your_package_name\n</code></pre> <p>N'oubliez pas de red\u00e9marrer votre noyau Jupyter par la suite, pour acc\u00e9der \u00e0 de nouvelles trousses.</p> Assurez-vous de red\u00e9marrer le noyau Jupyter apr\u00e8s l'installation d'un nouveau logiciel <p>Si vous installez un logiciel dans un terminal, mais que votre noyau Jupyter \u00e9tait d\u00e9j\u00e0 en cours d'ex\u00e9cution, il ne sera pas mis \u00e0 jour.</p> Y a-t-il quelque chose que vous ne pouvez pas installer? <p>Si vous avez besoin d'installer quelque chose, communiquez avec nous ou ouvrir une question GitHub. Nous pouvons l'ajouter au logiciel par d\u00e9faut.</p>"},{"location":"1-Experiences/Jupyter/#une-fois-que-vous-avez-les-bases","title":"Une fois que vous avez les bases ...","text":""},{"location":"1-Experiences/Jupyter/#entrer-et-sortir-des-donnees-de-jupyter","title":"Entrer et sortir des donn\u00e9es de Jupyter","text":"<p>Vous pouvez t\u00e9l\u00e9charger et charger des donn\u00e9es vers ou depuis JupyterHub directement dans le menu. Il y a un bouton de chargement en haut, et vous pouvez cliquer avec le bouton droit de la souris sur la plupart des fichiers ou dossiers pour les t\u00e9l\u00e9charger.</p>"},{"location":"1-Experiences/Jupyter/#stockage-partage-en-compartiment","title":"Stockage partag\u00e9 en compartiment","text":"<p>Il y a aussi un dossier <code>minio</code> mont\u00e9 dans votre r\u00e9pertoire personnel qui contient les fichiers dans MinIO.</p> <p>Consultez la section sur le stockage rubrique pour plus de d\u00e9tails</p>"},{"location":"1-Experiences/Kubeflow/","title":"Aper\u00e7u","text":""},{"location":"1-Experiences/Kubeflow/#que-fait-kubeflow","title":"Que fait Kubeflow?","text":"<p>Kubeflow ex\u00e9cute vos espaces de travail. Vous pouvez avoir des serveurs de bloc-notes (appel\u00e9s serveurs Jupyter), et vous pouvez y cr\u00e9er des analyses en R et Python avec des visuels interactifs. Vous pouvez enregistrer et charger des donn\u00e9es, t\u00e9l\u00e9charger des donn\u00e9es, et cr\u00e9er des espaces de travail partag\u00e9s pour votre \u00e9quipe.</p> <p></p> <p>Commen\u00e7ons sans plus tarder!</p>"},{"location":"1-Experiences/Kubeflow/#creer-un-serveur","title":"Cr\u00e9er un serveur","text":""},{"location":"1-Experiences/Kubeflow/#se-connecter-a-kubeflow","title":"Se connecter \u00e0 Kubeflow","text":""},{"location":"1-Experiences/Kubeflow/#didacticiel-video","title":"Didacticiel vid\u00e9o","text":"<p>Cette vid\u00e9o n'est pas \u00e0 jour, certaines choses pourraient avoir chang\u00e9 depuis.</p> <p></p>"},{"location":"1-Experiences/Kubeflow/#installation","title":"Installation","text":""},{"location":"1-Experiences/Kubeflow/#connectez-vous-a-kubeflow","title":"Connectez-vous \u00e0 Kubeflow","text":"<p>Connectez-vous au portail Azure \u00e0 l'aide de vos identifiants cloud</p> <p>Vous devez vous connecter au portail Azure  en utilisant vos informations d'identification StatCan .<code>first.lastname@cloud.statcan.ca</code> ou  en utilisant vos informations d'identification StatCan  <code>first.lastname@statcan.gc.ca</code>. Vous pouvez le faire en utilisant Portail Azure. </p> <ul> <li>Se connecter \u00e0 Kubeflow</li> </ul> <ul> <li>Acc\u00e9dez \u00e0 l'onglet Serveurs bloc-notes</li> </ul> <p></p> <ul> <li>Puis clique + Nouveau serveur</li> </ul>"},{"location":"1-Experiences/Kubeflow/#configuration-de-votre-serveur","title":"Configuration de votre serveur","text":"<ul> <li>Vous obtiendrez un mod\u00e8le pour cr\u00e9er votre serveur de bloc-notes. Remarque   : le nom de votre serveur doit \u00eatre en lettres minuscules avec des tirets.   Pas d'espaces, et non souligne.</li> </ul> <ul> <li>Vous devrez choisir une image. V\u00e9rifiez le nom des images et choisissez-en une   qui correspond \u00e0 ce que tu veux faire. (Vous ne savez pas lequel choisir ?   V\u00e9rifiez vos options ici.)</li> </ul> <ul> <li>Si vous souhaitez utiliser un GPU, v\u00e9rifiez si l'image indique <code>cpu</code> ou <code>gpu</code>.</li> </ul>"},{"location":"1-Experiences/Kubeflow/#cpu-et-memoire","title":"CPU et m\u00e9moire","text":"<ul> <li> <p>Au moment de la r\u00e9daction (23 d\u00e9cembre, 2021), il existe deux types   d'ordinateurs dans la grappe</p> <ul> <li>CPU: <code>D16s v3</code> (16 CPU , 64 G m\u00e9moire; 15 CPU et 48 G m\u00e9moire sont   disponible pour l'utilisateur, 1 CPU et 16 G m\u00e9moire sont r\u00e9serv\u00e9s pour   l'utilisation du syst\u00e8me)</li> <li>GPU: <code>NC6s_v3</code> (6 CPU , 112 G m\u00e9moire, 1 GPU; 96 G de m\u00e9moire disponible   pour l'utilisateur, 16 G sont r\u00e9serv\u00e9s pour l'utilisation du syst\u00e8me)</li> </ul> </li> </ul> <p>Lors de la cr\u00e9ation d'un serveur de bloc-notes, le syst\u00e8me vous limitera aux sp\u00e9cifications maximales ci-dessus. Pour les serveurs de bloc-notes CPU, vous pouvez sp\u00e9cifier la quantit\u00e9 exacte de CPU et de m\u00e9moire dont vous avez besoin. Cela vous permet de r\u00e9pondre \u00e0 vos besoins de calcul tout en minimisant les co\u00fbts. Pour un serveur portable GPU, vous obtiendrez toujours le serveur complet (6 c\u0153urs CPU, 96 Gio de m\u00e9moire accessible et 1 GPU).</p> <p>\u00c0 l'avenir, il se peut que des machines plus grandes soient disponibles, vous pourriez donc avoir des restrictions plus souples.</p> <p>Bogue de cr\u00e9ation de n\u0153ud lent.</p> <p>En raison d'un bug avec le pare-feu, la cr\u00e9ation d'un nouveau n\u0153ud peut \u00eatre tr\u00e8s lente dans certains cas (jusqu'\u00e0 quelques heures). Un correctif pour ce probl\u00e8me est en cours.</p> <p>Utilisez les machines GPU de mani\u00e8re responsable</p> <p>Il y a moins de machines GPU que de machines CPU, alors utilisez-les de mani\u00e8re responsable.</p>"},{"location":"1-Experiences/Kubeflow/#stockage-de-vos-donnees","title":"Stockage de vos donn\u00e9es","text":"<p>-Vous aurez envie de cr\u00e9er un volume de donn\u00e9es ! Vous pourrez enregistrer votre travail ici, et si vous \u00e9teignez votre serveur, vous pourrez simplement remonter vos anciennes donn\u00e9es en entrant le nom de votre ancien disque. Il est important que vous vous souveniez du nom du volume.</p> <p></p> <p>V\u00e9rifiez les anciens volumes en regardant l'option Existant</p> <p>Lorsque vous cr\u00e9ez votre serveur vous avez la possibilit\u00e9 de r\u00e9utiliser un ancien volume ou en cr\u00e9er un nouveau. Vous souhaitez probablement r\u00e9utiliser votre ancien volume.</p>"},{"location":"1-Experiences/Kubeflow/#et-creer","title":"Et... Cr\u00e9er!!!","text":"<ul> <li>Si vous \u00eates satisfait des param\u00e8tres, vous pouvez maintenant cr\u00e9er le serveur   ! Cela pourrait prenez quelques minutes pour d\u00e9marrer en fonction des   ressources que vous avez demand\u00e9es. (GPU prendre plus de temps.)</li> </ul> <p>Votre serveur est en cours d'ex\u00e9cution</p> <p>Si tout se passe bien, votre serveur devrait fonctionner !!! Vous aurez maintenant le possibilit\u00e9 de se connecter, et essayer Jupyter!</p>"},{"location":"1-Experiences/Kubeflow/#une-fois-que-vous-avez-les-bases","title":"Une fois que vous avez les bases...","text":""},{"location":"1-Experiences/Kubeflow/#partagez-votre-espace-de-travail","title":"Partagez votre espace de travail","text":"<p>Dans Kubeflow, chaque utilisateur dispose d'un espace de noms qui contient son travail (son serveurs de blocs-note, pipelines, disques, etc.). Votre espace de nom vous appartient, mais peut \u00eatre partag\u00e9 si vous souhaitez collaborer avec d'autres. Pour plus de d\u00e9tails sur collaboration sur la plateforme, voir Collaboration.</p>"},{"location":"1-Experiences/MLflow/","title":"Aper\u00e7u","text":"<p>!!! danger \"MLflow a \u00e9t\u00e9 retir\u00e9 du projet AAW.     Si vous en avez besoin, contactez l'\u00e9quipe de d\u00e9veloppement\"</p> <p>MLflow s'agit d'une plateforme libre pour la gestion du cycle de vie de l'apprentissage automatique. C'est un \"registre de mod\u00e8les\" pour stocker vos mod\u00e8les d'apprentissage automatique et les m\u00e9triques associ\u00e9es. Vous pouvez utiliser l'interface web pour examiner vos mod\u00e8les, et vous pouvez utiliser son API REST pour enregistrer vos mod\u00e8les depuis Python, en utilisant le [paquet mlflow pip] (https://pypi.org/project/mlflow/).</p> <p></p>"},{"location":"1-Experiences/RStudio/","title":"RStudio","text":"<p>Vous pouvez utiliser l'image <code>rstudio</code> pour obtenir un environnement RStudio!</p> <p></p> <p>Vous pouvez installer les paquets <code>R</code> ou <code>python</code> avec <code>conda</code> ou <code>install.packages()</code>.</p>"},{"location":"1-Experiences/RStudio/#r-shiny","title":"R-Shiny","text":"<p>Vous pouvez aussi utiliser <code>Shiny</code>! Et le tableau de bord appara\u00eetra dans une nouvelle fen\u00eatre.</p> <p></p>"},{"location":"1-Experiences/Selectionner-une-Image/","title":"S\u00e9lectionner une Image pour votre Serveur bloc-notes","text":"<p>Selon votre projet ou votre utilisation souhait\u00e9e du serveur bloc-notes, certaines images seront plus appropri\u00e9es que d'autres.</p> <p>Ce qui suit passera en revue quelques caract\u00e9ristiques de chaque image pour vous aider \u00e0 choisir.</p> <p>Lors de la s\u00e9lection, vous avez 3 options principales:</p> <ul> <li>Bloc-notes Jupyter (CPU, TensorFlow, PyTorch)</li> <li>RStudio</li> <li>Bureau virtuel (r, Geomatics)</li> </ul>"},{"location":"1-Experiences/Selectionner-une-Image/#jupyter","title":"Jupyter","text":"<p>Les Bloc-notes Jupyter sont utilis\u00e9s pour cr\u00e9er et partager des documents interactifs qui contiennent un m\u00e9lange de code en direct, de visualisations et de texte. Ceux-ci peuvent \u00eatre \u00e9crits en <code>Python</code>,<code>Julia</code> ou <code>R</code>.</p> <p></p> La plupart des utilisations comprennent: <p>la transformation de donn\u00e9es, la simulation num\u00e9rique, la mod\u00e9lisation statistique, l'apprentissage automatique et autres.</p> <p>Ceux-ci s'agit d'un excellent outil pour l'analyse, y compris l'apprentissage machine. L'image <code>jupyterlab-cpu</code> fournit une bonne exp\u00e9rience de base pour <code>python</code>, y compris des paquets tels que <code>numpy</code>, <code>pandas</code> et <code>scikit-learn</code>. Si vous \u00eates int\u00e9ress\u00e9 sp\u00e9cifiquement par TensorFlow ou PyTorch, nous avons \u00e9galement les images <code>jupyterlab-tensorflow</code> et<code>jupyterlab-pytorch</code> qui viennent avec ces outils pr\u00e9-install\u00e9s.</p> <p>Pour l'image <code>jupyterlab-pytorch</code>, les packages PyTorch (torch, torchvision et torchaudio) sont install\u00e9s dans l'environnement conda <code>torch</code>. Vous devez activer cet environnement pour utiliser PyTorch.</p> <p>Pour les images <code>jupyterlab-cpu</code>, <code>jupyterlab-tensorflow</code> et <code>jupyterlab-pytorch</code>, dans le shell par d\u00e9faut, la commande <code>conda activate</code> peut ne pas fonctionner. Cela est d\u00fb au fait que l'environnement n'est pas correctement initialis\u00e9. Dans ce cas, ex\u00e9cutez \u00ab\u00a0bash\u00a0\u00bb, vous devriez voir le logo AAW et quelques instructions apparaissent. Apr\u00e8s cela, \"conda activate\" devrait fonctionner correctement. Si vous voyez le logo AAW au d\u00e9marrage, cela signifie que l'environnement est correctement initialis\u00e9 et que \u00ab\u00a0conda activate\u00a0\u00bb devrait fonctionner correctement. Un correctif pour ce bogue est en pr\u00e9paration, une fois cela corrig\u00e9, ce paragraphe sera supprim\u00e9.</p> <p>Chaque image est pr\u00e9charg\u00e9e avec VS Code dans le navigateur si vous pr\u00e9f\u00e9rez une exp\u00e9rience IDE compl\u00e8te.</p>"},{"location":"1-Experiences/Selectionner-une-Image/#rstudio","title":"RStudio","text":"<p>RStudio vous offre un environnement de d\u00e9veloppement int\u00e9gr\u00e9 sp\u00e9cifiquement pour <code>R</code>. Si vous codez en <code>R</code>, il s'agit g\u00e9n\u00e9ralement du serveur bloc-notes utiliser. Utilisez l'image <code>rstudio</code> pour obtenir un environnement RStudio.</p> <p></p>"},{"location":"1-Experiences/Selectionner-une-Image/#bureau-virtuel","title":"Bureau virtuel","text":"<p>Pour une exp\u00e9rience Ubuntu compl\u00e8te, deux versions du Bureau virtuel sont disponible. Ceux-ci sont pr\u00e9charg\u00e9s avec Python et R, mais sont livr\u00e9s dans un exp\u00e9rience typique qui est \u00e9galement fournie avec Firefox, VS Code et les outils Open Office. Le syst\u00e8me d'exploitation est Ubuntu 18.04 avec l'environnement de bureau XFCE.</p> <p><code>remote-desktop-r</code> inclut R et RStudio mais si vous avez besoin d'outils de g\u00e9omatique pour R, choisissez la version <code>remote-desktop-geomatics</code> de cette image.</p> <p></p>"},{"location":"2-Publication/Dash/","title":"Bien d\u00e9marrer avec Dash!","text":"<p>Pour les outils de visualisation de donn\u00e9es, nous allons utiliser Dash. Dash est un excellent outil utilis\u00e9 par plusieurs pour l'analyse des donn\u00e9es, l'exploration des donn\u00e9es, la visualisation, la mod\u00e9lisation, le contr\u00f4le des instruments et la cr\u00e9ation de rapports.</p> <p>L'exemple suivant d\u00e9montre une application Dash hautement r\u00e9active et personnalis\u00e9e avec peu de code.</p> <p>Ex\u00e9cution de votre serveur de bloc-notes et acc\u00e8s au port</p> <p>Lors de l'ex\u00e9cution de tout outil \u00e0 partir de votre bloc-notes Jupyter qui affiche un site web sur un port, vous ne serez pas en mesure d'y acc\u00e9der simplement \u00e0 partir de <code>http://localhost:5000/</code> comme normalement sugg\u00e9r\u00e9 dans la sortie lors de l'ex\u00e9cution de l'application web.</p> <p>Pour acc\u00e9der au serveur web, vous devrez utiliser l'URL de base. Dans le terminal du bloc-notes ex\u00e9cutez le suivant:</p> <pre><code>echo https://kubeflow.covid.cloud.statcan.ca${JUPYTER_SERVER_URL:19}proxy/5000/\n</code></pre>"},{"location":"2-Publication/Dash/#visualisation-de-donnees-avec-dash","title":"Visualisation de donn\u00e9es avec Dash","text":"<p>Dash permet de facilement cr\u00e9er une interface graphique interactive autour de votre code d'analyse de donn\u00e9es. Le suivant s'agit d'un exemple de mise en page avec une figure et curseur \u00e0 partir de Dash.</p> <p></p> <pre><code># installations requis\npip3 install dash==1.16.3\npip3 install pandas\n</code></pre> <pre><code># app.py\n#!/usr/bin/env python3\nimport dash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input, Output\nimport plotly.express as px\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv')\nexternal_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\napp = dash.Dash(__name__, external_stylesheets=external_stylesheets)\napp.layout = html.Div([\ndcc.Graph(id='graph-with-slider'),\ndcc.Slider(\nid='year-slider',\nmin=df['year'].min(),\nmax=df['year'].max(),\nvalue=df['year'].min(),\nmarks={str(year): str(year) for year in df['year'].unique()},\nstep=None\n)\n])\n@app.callback(\nOutput('graph-with-slider', 'figure'),\n[Input('year-slider', 'value')])\ndef update_figure(selected_year):\nfiltered_df = df[df.year == selected_year]\nfig = px.scatter(filtered_df, x=\"gdpPercap\", y=\"lifeExp\",\nsize=\"pop\", color=\"continent\", hover_name=\"country\",\nlog_x=True, size_max=55)\nfig.update_layout(transition_duration=500)\nreturn fig\nif __name__ == '__main__':\napp.run_server(debug=True)\n</code></pre>"},{"location":"2-Publication/Dash/#executer-votre-application","title":"Ex\u00e9cuter votre application","text":"<pre><code>python app.py\n# ou vous pouvez utiliser:\nexport FLASK_APP=app.py\nflask run\n</code></pre>"},{"location":"2-Publication/Datasette/","title":"Aper\u00e7u","text":"<p>Datasette est une API JSON instantan\u00e9e pour vos bases de donn\u00e9es SQLite qui permet d'explorer la BD et d'ex\u00e9cuter des requ\u00eates SQL de mani\u00e8re plus interactive.</p> <p>Vous pouvez trouver une liste d'exemples de datasettes ici.</p> <p>\u00c9cosyst\u00e8me de Datasette</p> <p>Il existe toutes sortes d'outils pour convertir des donn\u00e9es depuis et vers sqlite. ici. Par exemple, vous pouvez charger des fichiers de forme dans sqlite, ou cr\u00e9er des graphes Vega \u00e0 partir d'une base de donn\u00e9es sqlite. SQLite fonctionne bien avec <code>R</code>, <code>Python</code>, et plusieurs autres outils.</p>"},{"location":"2-Publication/Datasette/#exemple-datasette","title":"Exemple Datasette","text":"<p>Voici quelques captures d'\u00e9cran du Datasette global-power-plants, vous pouvez pr\u00e9visualiser et explorer les donn\u00e9es dans le navigateur, que ce soit par des clics ou des requ\u00eates SQL.</p> <p></p> <p>Vous pouvez m\u00eame explorer des cartes au sein de l'outil!</p> <p>Ex\u00e9cuter des requ\u00eates SQL</p>"},{"location":"2-Publication/Datasette/#didacticiel-video","title":"Didacticiel vid\u00e9o","text":""},{"location":"2-Publication/Datasette/#commencer","title":"Commencer","text":""},{"location":"2-Publication/Datasette/#installation-des-datasettes","title":"Installation des Datasettes","text":"<p>Pour visualiser votre base de donn\u00e9es dans votre bloc-notes Jupyter, cr\u00e9ez le fichier bash suivant dans votre r\u00e9pertoire de projet, rendre le fichier ex\u00e9cutable en utilisant <code>chmod +x start.sh</code> puis ex\u00e9cutez-le avec la commande <code>./start.sh</code>. Acc\u00e9dez au serveur web en utilisant le URL de base avec le num\u00e9ro de port que vous utilisez dans le fichier ci-dessous.</p> <p>start.sh</p> <pre><code>#!/bin/bash\n# This script just starts Datasette with the correct URL, so\n# that you can use it within kubeflow.\n# Get an example database\nwget https://github.com/StatCan/aaw-contrib-r-notebooks/raw/master/database-connections/latin_phrases.db\n\n# If you have your own database, you can change this line!\nDATABASE=latin_phrases.db\n\nexport BASE_URL=\"https://kubeflow.covid.cloud.statcan.ca${JUPYTER_SERVER_URL:19}proxy/8001/\"\necho \"Base url: ${BASE_URL}\"\ndatasette $DATABASE --cors --config max_returned_rows:100000 --config sql_time_limit_ms:5500 --config base_url:${BASE_URL}\n</code></pre> <p>Regardez ce tutoriel</p> <p>Un utilisateur de la plateforme a utilis\u00e9 Datasette avec un tableau de bord. Voir la vid\u00e9o pour une d\u00e9monstration.</p> <p>Ex\u00e9cuter le serveur de votre bloc-notes et acc\u00e9der au port</p> <p>Lorsque vous ex\u00e9cutez un outil depuis votre bloc-notes Jupyter qui affiche un site web sur un port, vous ne serez pas en mesure d'y acc\u00e9der simplement \u00e0 partir de <code>http://localhost:5000/</code> comme normalement sugg\u00e9r\u00e9 dans la sortie lors de l'ex\u00e9cution de l'application web.</p> <p>Pour acc\u00e9der au serveur web, vous devrez utiliser l'URL de base. Dans le terminal du bloc-note, ex\u00e9cutez:</p> <pre><code>echo https://kubeflow.covid.cloud.statcan.ca${JUPYTER_SERVER_URL:19}proxy/5000/\n</code></pre>"},{"location":"2-Publication/PowerBI/","title":"Chargement des donn\u00e9es dans Power BI","text":"<p>Nous ne proposons pas de serveur Power BI, mais vous pouvez extraire vos donn\u00e9es dans Power BI \u00e0 partir de notre syst\u00e8me de stockage et les utiliser comme une trame de donn\u00e9es <code>pandas</code>.</p> <p></p>"},{"location":"2-Publication/PowerBI/#installation","title":"Installation","text":""},{"location":"2-Publication/PowerBI/#ce-dont-vous-aurez-besoin","title":"Ce dont vous aurez besoin","text":"<ol> <li>Un ordinateur avec Power BI et Python 3.6</li> <li>Vos <code>ACCESS_KEY</code> et <code>SECRET_KEY</code> MinIO (voir Stockage)</li> </ol>"},{"location":"2-Publication/PowerBI/#connectez-vous","title":"Connectez-vous","text":""},{"location":"2-Publication/PowerBI/#configurez-power-bi","title":"Configurez Power BI","text":"<p>Ouvrez votre syst\u00e8me Power BI et ouvrez d\u00e9marrage rapide de Power BI dans votre \u00e9diteur de texte pr\u00e9f\u00e9r\u00e9.</p> <p>Assurez-vous que <code>pandas</code>, <code>boto3</code> et <code>numpy</code> sont install\u00e9s et que vous utilisez le bon environnement virtuel Conda (le cas \u00e9ch\u00e9ant).</p> <p></p> <p>Ensuite, assurez-vous que Power BI utilise le bon environnement Python. Vous pouvez modifier cet \u00e9l\u00e9ment \u00e0 partir du menu des options. Le chemin d'acc\u00e8s exact est indiqu\u00e9 dans le guide de d\u00e9marrage rapide.</p>"},{"location":"2-Publication/PowerBI/#modifiez-votre-script-python","title":"Modifiez votre script Python","text":"<p>Ensuite, modifiez votre script Python pour utiliser vos <code>ACCESS_KEY</code> et <code>SECRET_KEY</code> MinIO, puis cliquez sur \u00ab Obtenir des donn\u00e9es \u00bb et copiez-le en tant que script Python.</p> <p></p>"},{"location":"2-Publication/R-Shiny/","title":"Aper\u00e7u","text":"<p>R-Shiny est un paquet R qui facilite la cr\u00e9ation d'applications Web interactives dans R. Nous g\u00e9rons le serveur R-Shiny, et il est tr\u00e8s facile de mettre votre tableau de bord sur le Plate-forme.</p> <p></p>"},{"location":"2-Publication/R-Shiny/#installation","title":"Installation","text":""},{"location":"2-Publication/R-Shiny/#envoyez-simplement-une-demande-dextraction","title":"Envoyez simplement une demande d'extraction!","text":"<p>Il vous suffit d'envoyer une demande d'extraction \u00e0 notre r\u00e9pertoire de tableaux de bord R-Shiny. Placez votre r\u00e9pertoire dans un dossier portant le nom que vous voulez utiliser (p. ex. tableau-bord-qualit\u00e9-air). Ensuite, nous l'approuverons et il sera mis en ligne.</p> <p>Si vous avez d'autres biblioth\u00e8ques R \u00e0 installer, envoyez votre liste \u00e0 r\u00e9pertoire R-Shiny en cr\u00e9ant un dossier GitHub, et nous ajouterons les d\u00e9pendances.</p> <p></p> <p>Voir le tableau de bord ci-dessus</p> <p>Le tableau de bord ci-dessus se trouve dans GitHub. Jetez un coup d'\u0153il \u00e0 la source et voyez le tableau de bord en direct.</p>"},{"location":"2-Publication/R-Shiny/#une-fois-que-vous-avez-les-bases","title":"Une fois que vous avez les bases...","text":""},{"location":"2-Publication/R-Shiny/#integration-de-tableaux-de-bord-sur-vos-sites-web","title":"Int\u00e9gration de tableaux de bord sur vos sites Web","text":"<p>Int\u00e9gration de tableaux de bord sur d'autres sites</p> <p>Nous n'avons pas encore eu l'occasion de l'examiner ni d'en faire un prototype. Toutefois, si vous avez un cas d'utilisation, n'h\u00e9sitez pas \u00e0 communiquer avec l'ing\u00e9nierie. Nous travaillerons avec vous pour trouver une solution.</p>"},{"location":"2-Publication/Sur-mesure/","title":"Applications Web personnalis\u00e9es","text":"<p>Nous pouvons tout d\u00e9ployer, dans la mesure o\u00f9 il s'agit de logiciel libre, et nous pouvons le mettre dans un conteneur Docker (p. ex. applications Node.js, Flask, Dash).</p> <p></p> <p>Voir le code de source de cette application</p> <p>Nous int\u00e9grons ces types d'applications au serveur au moyen de GitHub. La source de l'application ci-dessus est ici : <code>StatCan/covid19</code>.</p>"},{"location":"2-Publication/Sur-mesure/#comment-faire-heberger-votre-application","title":"Comment faire h\u00e9berger votre application","text":"<p>Si vous avez d\u00e9j\u00e0 une application Web dans un r\u00e9pertoire Git, d\u00e8s qu'elle est plac\u00e9e dans un conteneur Docker, nous pouvons int\u00e9grer le r\u00e9pertoire Git dans le r\u00e9pertoire GitHub de StatCan et pointer une URL vers elle. Pour la mettre \u00e0 jour, il vous suffit d'interagir avec le r\u00e9pertoire GitHub de StatCan au moyen de demandes d'extraction.</p> <p>Si vous avez des questions, n'h\u00e9sitez pas \u00e0 communiquer avec nous.</p>"},{"location":"3-Pipelines/Kubeflow-Pipelines/","title":"Vue d'ensemble","text":"<p>Kubeflow Pipelines est une plateforme de cr\u00e9ation de flux de production d'apprentissage automatique pouvant \u00eatre d\u00e9ploy\u00e9s dans un environnement Kubernetes. Il permet de cr\u00e9er des pipelines qui encapsulent les flux de production analytiques (transformation de donn\u00e9es, mod\u00e8les de formation, construction d'\u00e9l\u00e9ments visuels, etc.). Ces pipelines peuvent \u00eatre mis en commun, r\u00e9utilis\u00e9s et programm\u00e9s. Ils sont cr\u00e9\u00e9s de fa\u00e7on \u00e0 \u00eatre ex\u00e9cut\u00e9s avec les calculs fournis par Kubernetes.</p> <p>Dans le contexte de l'espace de travail en analytique avanc\u00e9e, vous pouvez interagir avec les pipelines Kubeflow par l'entremise :</p> <ul> <li>de l'interface utilisateur de Kubeflow, o\u00f9, \u00e0   partir du menu Pipelines, vous pouvez t\u00e9l\u00e9charger des pipelines, visualiser   les pipelines que vous poss\u00e9dez et leurs r\u00e9sultats, etc.</li> </ul> <ul> <li>de la trousse SDK   en Python de Kubeflow Pipelines, accessible dans les serveurs de bloc-notes   Jupyter, o\u00f9 vous pouvez d\u00e9finir vos composants et pipelines, les soumettre   pour les ex\u00e9cuter imm\u00e9diatement, ou m\u00eame les enregistrer pour plus tard.</li> </ul> Des exemples suppl\u00e9mentaires dans les bloc-notes <p>Des exemples plus exhaustifs de pipelines produits express\u00e9ment pour cette plateforme sont accessibles dans GitHub (et dans chaque serveur de bloc-notes \u00e0 <code>/jupyter-notebooks</code>). Vous pouvez \u00e9galement consulter des sources publiques.</p> <p>Voyez le documentation officiel de Kubeflow pour obtenir une explication g\u00e9n\u00e9rale d\u00e9taill\u00e9e de Kubeflow.</p> <p></p>"},{"location":"3-Pipelines/Kubeflow-Pipelines/#quest-ce-quun-pipeline-et-comment-fonctionne-t-il","title":"Qu'est-ce qu'un pipeline et comment fonctionne-t-il?","text":"<p>Dans Kubeflow Pipelines, un pipeline comprend un ou plusieurs composants de pipeline encha\u00een\u00e9s pour former un flux de production. Les composants sont comme des fonctions que le pipeline connecte ensemble.</p> <p>Le pipeline d\u00e9crit l'ensemble du flux de production de ce que vous souhaitez accomplir, tandis que les composants de pipeline d\u00e9crivent chacune des \u00e9tapes distinctes de ce processus (comme le fait d'extraire des colonnes d'un stock de donn\u00e9es, de transformer des donn\u00e9es ou d'entra\u00eener un mod\u00e8le). Chaque composant doit \u00eatre modulaire et id\u00e9alement r\u00e9utilisable.</p> <p>Essentiellement, chaque composant a :</p> <ul> <li>une application autonome, pr\u00e9sent\u00e9e sous forme d'image de menu fixe   (https://docs.docker.com/get-started/), pour effectuer le travail proprement   dit .le code dans l'image de menu fixe peut \u00eatre une s\u00e9quence de commandes en   langage naturel, un script Python ou tout autre code pouvant \u00eatre ex\u00e9cut\u00e9 \u00e0   partir d'un terminal Linux</li> <li>une description de la mani\u00e8re dont Kubeflow Pipelines ex\u00e9cute le code   (l'emplacement de l'image, les arguments de la ligne de commande qu'il   accepte, les r\u00e9sultats qu'il produit), sous forme de fichier YAML.</li> </ul> <p>Un pipeline d\u00e9finit ensuite la logique de connexion des composants, par exemple :</p> <ol> <li>Ex\u00e9cuter <code>ComposantA</code></li> <li>transmettre le r\u00e9sultat du <code>ComposantA</code> au <code>ComposantB</code> et au <code>ComposantC</code></li> <li>...</li> </ol> <p>Exemple d'un pipeline</p> <p>Voici un exemple :</p> <pre><code>#!/bin/python3\ndsl.pipeline(name=\"Estimer Pi\",\n    description=\"Estimer Pi au moyen d'un mod\u00e8le Map-Reduce\")\ndef compute_pi():\n    # Cr\u00e9er un \"exemple\" d'op\u00e9ration pour chaque valeur de d\u00e9part\n    # transmise au pipeline\n    seeds = (1,2,3,4,5,6,7,8,9,10)\n    sample_ops = [sample_op(seed) for seed in seeds]\n\n    # Obtenir les r\u00e9sultats avant de les transmettre \u00e0 deux pipelines\n    # distincts. Les r\u00e9sultats sont extraits des fichiers\n    # `output_file.json` et sont disponibles \u00e0 partir des instances\n    # `sample_op` par l'entremise de l'attribut `.outputs`.\n    outputs = [s.outputs['output'] for s in sample_ops]\n\n    _generate_plot_op = generate_plot_op(outputs)\n    _average_op = average_op(outputs)\n</code></pre> <p>Vous pouvez trouver le pipeline complet dans l'exemple <code>map-reduce-pipeline</code>.</p>"},{"location":"3-Pipelines/Kubeflow-Pipelines/#definir-et-executer-votre-premier-pipeline","title":"D\u00e9finir et ex\u00e9cuter votre premier pipeline","text":"<p>Bien que les pipelines et les composants soient d\u00e9finis par des fichiers YAML, la trousse SDK en Python vous permet de les d\u00e9finir \u00e0 partir du code Python. Voici un exemple de d\u00e9finition d'un pipeline simple en utilisant la trousse SDK en Python.</p> <p>L'objectif de notre pipeline est de calculer, au moyen de cinq nombres, les valeurs suivantes :</p> <ol> <li>la moyenne des trois premiers nombres;</li> <li>la moyenne des deux derniers nombres;</li> <li>la moyenne des r\u00e9sultats de (1) et de (2).</li> </ol> <p>Pour ce faire, nous d\u00e9finissons un pipeline qui utilise notre composant moyen pour effectuer les calculs.</p> <p>Le composant moyen est d\u00e9fini par une image de menu fixe au moyen d'un script Python qui :</p> <ul> <li>accepte un ou plusieurs nombres comme arguments de ligne de commande</li> <li>renvoie la moyenne de ces nombres, enregistr\u00e9e dans le fichier <code>out.txt</code> dans   son conteneur.</li> </ul> <p>Pour indiquer \u00e0 Kubeflow Pipelines comment utiliser cette image, nous d\u00e9finissons notre composant moyen par l'entremise d'un <code>ContainerOp</code>, qui indique \u00e0 Kubeflow l'interface API de notre image. L'instance <code>ContainerOp</code> d\u00e9finit l'emplacement de l'image du menu fixe, la fa\u00e7on de lui transmettre des arguments et les r\u00e9sultats \u00e0 extraire du conteneur. Pour utiliser r\u00e9ellement ces <code>ContainerOp</code> dans notre pipeline, nous cr\u00e9ons des fonctions de fabrique comme <code>average_op</code> (car nous voudrons probablement plus d'un composant moyen).</p> <pre><code>from kfp import dsl\ndef average_op(\\*numbers):\n\"\"\" Fabrique de ContainerOp moyen\n    Accepte un nombre arbitraire de nombres d'entr\u00e9e, en renvoyant un ContainerOp\n    qui transmet ces nombres \u00e0 l'image du menu fixe sous-jacent pour faire la\n    moyenne\n    Renvoie le r\u00e9sultat recueilli \u00e0 partir du fichier ./out.txt \u00e0 l'int\u00e9rieur du\n    conteneur\n    \"\"\"\n# Validation d'entr\u00e9e\nif len(numbers) &lt; 1:\nraise ValueError(\"Doit pr\u00e9ciser au moins un nombre \u00e0 partir duquel calculer la moyenne\")\nreturn dsl.ContainerOp(\nname=\"averge\", # \u00c9l\u00e9ment affich\u00e9 dans la visionneuse de pipeline\nimage=\"k8scc01covidacr.azurecr.io/kfp-components/average:v1\", # L'image\nex\u00e9cut\u00e9e par Kubeflow Pipelines pour faire le travail arguments=numbers,\n#transmet chaque nombre comme un argument de ligne de commande (cha\u00eene) distinct\n# Le script \u00e0 l'int\u00e9rieur du conteneur enregistre le r\u00e9sultat (sous forme de cha\u00eene de caract\u00e8res) dans le fichier out.txt, que\n# Kubeflow Pipelines lit pour nous et r\u00e9cup\u00e8re sous forme de cha\u00eene.\nfile_outputs={'data': './out.txt'},\n)\n</code></pre> <p>Nous d\u00e9finissons notre pipeline comme une fonction Python qui utilise les fabriques de <code>ComponentOp</code> ci-dessus, d\u00e9cor\u00e9es par l'\u00e9l\u00e9ment d\u00e9coratif <code>@dsl.pipeline</code>. Notre pipeline utilise notre composant moyen en lui transmettant des nombres. Puis, nous utilisons les r\u00e9sultats moyens en les transmettant \u00e0 des fonctions plus tard par l'acc\u00e8s \u00e0 <code>avg\\_\\*.output</code>.</p> <pre><code>@dsl.pipeline(\nname=\"nom de mon pipeline\"\n)\ndef my_pipeline(a, b, c, d, e):\n\"\"\"\n    Calcul de moyenne de pipeline, qui accepte cinq nombres et effectue quelques calculs de moyenne sur ceux-ci\n    \"\"\"\n# Calculer les moyennes pour deux groupes\navg_1 = average_op(a, b, c)\navg_2 = average_op(d, e)\n# Utiliser les r\u00e9sultats de \\_1 et de \\_2 pour calculer une moyenne globale\naverage_result_overall = average_op(avg_1.output, avg_2.output)\n</code></pre> <p>Enfin, nous enregistrons une d\u00e9finition YAML de notre pipeline pour la transmettre plus tard \u00e0 Kubeflow Pipelines. Ce fichier YAML d\u00e9crit \u00e0 Kubeflow Pipelines exactement comment ex\u00e9cuter notre pipeline. D\u00e9compressez-le et voyez par vous-m\u00eame!</p> <pre><code>from kfp import compiler\npipeline_yaml = 'pipeline.yaml.zip'\ncompiler.Compiler().compile(\nmy_pipeline,\npipeline_yaml\n) print(f\"D\u00e9finition de pipeline export\u00e9e vers {pipeline_yaml}\")\n</code></pre> <p>??? avertissement \"Kubeflow Pipelines est une b\u00eate paresseuse\".     Il est utile de garder \u00e0 l'esprit le calcul qui se produit lorsque vous     ex\u00e9cutez ce code Python par rapport \u00e0 ce qui se passe lorsque vous soumettez     le pipeline \u00e0 Kubeflow Pipelines. Bien que tout semble se produire     instantan\u00e9ment, essayez d'ajouter <code>print(avg_1.output)</code> au pipeline     ci-dessus et voyez ce qui se passe lorsque vous compilez votre pipeline. La     trousse SDK en Python que nous utilisons sert \u00e0 cr\u00e9er des pipelines, et non     \u00e0 les ex\u00e9cuter, de sorte que les r\u00e9sultats des composants ne seront jamais     disponibles lorsque vous ex\u00e9cuterez ce code Python. Ce point est abord\u00e9 plus     en d\u00e9tail plus loin, dans la section Comprendre l'ordre des calculs.</p> <p>Pour ex\u00e9cuter notre pipeline, nous d\u00e9finissons une exp\u00e9rience :</p> <pre><code>experiment_name = \"calcul de moyenne de pipeline\"\nimport kfp\nclient = kfp.Client()\nexp = client.create_experiment(name=experiment_name)\npl_params = { 'a': 5, 'b': 5, 'c': 8, 'd': 10, 'e': 18, }\n</code></pre> <p>Voici ce qui peut \u00eatre observ\u00e9 dans l'interface utilisateur de Kubeflow Pipelines :</p> <p></p> <p>Ensuite, nous ex\u00e9cutons une instance de notre pipeline en utilisant les arguments souhait\u00e9s :</p> <pre><code>import time\nrun = client.run_pipeline(\nexp.id, # Ex\u00e9cuter dans l'exp\u00e9rience ci-dessus\nexperiment_name + '-' + time.strftime(\"%Y%m%d-%H%M%S\"), # Donner un nom et une\nheure syst\u00e8me \u00e0 notre t\u00e2che unique pipeline_yaml, # Transmettre le .yaml.zip que\nnous avons cr\u00e9\u00e9 ci-dessus. Il d\u00e9finit le pipeline params=pl_params # Transmettre\nles param\u00e8tres en fonction desquels nous souhaitons ex\u00e9cuter le pipeline\n)\n</code></pre> <p>Voici ce que l'on peut \u00e9galement voir dans l'interface utilisateur :</p> <p></p> <p>Plus tard, lorsque nous souhaiterons r\u00e9utiliser le pipeline, nous pourrons transmettre diff\u00e9rents arguments et tout recommencer (et m\u00eame le r\u00e9utiliser \u00e0 partir de l'interface utilisateur de Kubeflow). Pour mieux comprendre cet exemple, ouvrez-le dans Kubeflow et essayez-le vous-m\u00eame.</p>"},{"location":"3-Pipelines/Kubeflow-Pipelines/#composants-legers","title":"Composants l\u00e9gers","text":"<p>En construction, malheureusement!</p>"},{"location":"3-Pipelines/Kubeflow-Pipelines/#comprendre-lordre-des-calculs","title":"Comprendre l'ordre des calculs","text":"<p>En construction, malheureusement!</p>"},{"location":"3-Pipelines/Machine-Learning/","title":"Mod\u00e8les d'apprentissage automatique","text":"<p>Les mod\u00e8les d'apprentissage automatique sont des algorithmes de calcul con\u00e7us pour apprendre automatiquement des mod\u00e8les et des relations \u00e0 partir de donn\u00e9es. Ces mod\u00e8les sont entra\u00een\u00e9s sur un ensemble de donn\u00e9es, qui est g\u00e9n\u00e9ralement une collection d'exemples ou d'instances, chacun d'entre eux se composant d'un ensemble de fonctionnalit\u00e9s ou de variables, ainsi que d'une variable cible ou d'une sortie.</p> <p>L'objectif d'un mod\u00e8le d'apprentissage automatique est d'identifier des mod\u00e8les et des relations au sein des donn\u00e9es qui peuvent \u00eatre utilis\u00e9s pour faire des pr\u00e9dictions ou des d\u00e9cisions concernant de nouvelles donn\u00e9es invisibles. Cela implique de d\u00e9velopper une repr\u00e9sentation math\u00e9matique de la relation entre les caract\u00e9ristiques d'entr\u00e9e et la variable de sortie, sur la base des mod\u00e8les observ\u00e9s dans les donn\u00e9es d'apprentissage. Une fois le mod\u00e8le entra\u00een\u00e9, il peut \u00eatre utilis\u00e9 pour faire des pr\u00e9dictions ou prendre des d\u00e9cisions concernant de nouvelles donn\u00e9es in\u00e9dites.</p> <p>Il existe plusieurs types de mod\u00e8les d'apprentissage automatique, chacun \u00e9tant con\u00e7u pour traiter diff\u00e9rents types de probl\u00e8mes ou de donn\u00e9es. Certains des types les plus courants de mod\u00e8les d'apprentissage automatique incluent :</p> <ol> <li> <p>Mod\u00e8les de r\u00e9gression : Les mod\u00e8les de r\u00e9gression sont utilis\u00e9s pour pr\u00e9dire des valeurs num\u00e9riques continues, telles que les cours des actions ou les prix des logements.</p> </li> <li> <p>Mod\u00e8les de classification : Les mod\u00e8les de classification sont utilis\u00e9s pour pr\u00e9dire des valeurs cat\u00e9gorielles discr\u00e8tes, par exemple si un client ach\u00e8tera ou non un produit.</p> </li> <li> <p>Mod\u00e8les de clustering : Les mod\u00e8les de clustering sont utilis\u00e9s pour identifier des groupes ou des clusters au sein d'un ensemble de donn\u00e9es en fonction des similitudes entre les instances.</p> </li> <li> <p>Mod\u00e8les de recommandation : Les mod\u00e8les de recommandation sont utilis\u00e9s pour recommander des produits ou des services aux utilisateurs en fonction de leur comportement ou de leurs pr\u00e9f\u00e9rences pass\u00e9s.</p> </li> <li> <p>R\u00e9seaux de neurones : Les r\u00e9seaux de neurones sont un type de mod\u00e8le d'apprentissage automatique con\u00e7u pour imiter la structure et la fonction du cerveau humain. Ils sont couramment utilis\u00e9s dans les applications de reconnaissance d'images, de reconnaissance vocale et de traitement du langage naturel.</p> </li> </ol> <p>Les mod\u00e8les d'apprentissage automatique peuvent \u00eatre biais\u00e9s</p> <p>Les mod\u00e8les d'apprentissage automatique sont un outil puissant pour analyser et faire des pr\u00e9dictions sur les donn\u00e9es, et ils ont un large \u00e9ventail d'applications dans des domaines tels que la finance, la sant\u00e9, le marketing, etc. Cependant, il est important de noter que les mod\u00e8les d'apprentissage automatique ne sont pas parfaits et peuvent parfois faire des erreurs ou produire des r\u00e9sultats biais\u00e9s. Par cons\u00e9quent, il est important d'\u00e9valuer et de tester soigneusement les mod\u00e8les d'apprentissage automatique avant de les utiliser dans des applications r\u00e9elles.</p>"},{"location":"3-Pipelines/Machine-Learning/#exemples","title":"Exemples","text":""},{"location":"3-Pipelines/Machine-Learning/#regression-lineaire","title":"R\u00e9gression lin\u00e9aire","text":"<p>R\u00e9gression lin\u00e9aire</p> <p>$$  \\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i + \\hat{\\epsilon}_i  $$</p> <p>O\u00f9 \\(\\hat{Y}_i\\) d\u00e9signe le \\(i\\)i\u00e8me estimateur de la vraie valeur \\(Y\\) en fonction de la \\(i\\)i\u00e8me p\u00e9riode d'apprentissage. Chaque \\(\\hat{\\beta}\\) est un param\u00e8tre \u00e0 apprendre. \\(\\hat{\\epsilon}_i\\) est la quantit\u00e9 de bruit autoris\u00e9e dans le mod\u00e8le et peut varier en fonction du nombre d'\u00e9poques d'entra\u00eenement indiqu\u00e9 par \\(i\\). Chaque \\(X_i\\) repr\u00e9sente le \\(i\\)i\u00e8me lot de donn\u00e9es d'apprentissage.</p> <p>Dans les mod\u00e8les statistiques classiques comme la r\u00e9gression lin\u00e9aire, l'objectif est de trouver une ligne qui correspond le mieux aux donn\u00e9es, nous permettant de faire des pr\u00e9dictions sur de nouveaux points de donn\u00e9es.</p> <p>\u00c0 mesure que la complexit\u00e9 du probl\u00e8me augmente, des algorithmes plus sophistiqu\u00e9s sont n\u00e9cessaires, tels que des arbres de d\u00e9cision, des machines \u00e0 vecteurs de support et des for\u00eats al\u00e9atoires. Cependant, ces m\u00e9thodes ont des limites et peuvent ne pas \u00eatre en mesure de capturer des mod\u00e8les complexes dans de grands ensembles de donn\u00e9es.</p>"},{"location":"3-Pipelines/Machine-Learning/#exemple-de-code","title":"Exemple de code","text":"PythonR linear_regression.py<pre><code>#!/usr/bin/env python\n# Charger les biblioth\u00e8ques requises\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n# Charger le jeu de donn\u00e9es\ndata = pd.read_csv('path/to/dataset.csv')\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nX_train, X_test, y_train, y_test = train_test_split(data.drop('target_variable', axis=1), data['target_variable'], test_size=0.2)\n# Former le mod\u00e8le de r\u00e9gression lin\u00e9aire\nlinear_model = LinearRegression()\nlinear_model.fit(X_train, y_train)\n# Faire des pr\u00e9dictions sur l'ensemble de test\ny_pred = linear_model.predict(X_test)\n# \u00c9valuer les performances du mod\u00e8le\nmse = mean_squared_error(y_test, y_pred)\nrmse = mse ** 0.5\nprint('Root Mean Squared Error:', rmse)\n</code></pre> <p>``` r title=\"linear_regression.r\" linenums=\"1\"</p>"},{"location":"3-Pipelines/Machine-Learning/#usrbinenv-rscript","title":"!/usr/bin/env Rscript","text":""},{"location":"3-Pipelines/Machine-Learning/#definir-une-graine-aleatoire-pour-la-reproductibilite","title":"D\u00e9finir une graine al\u00e9atoire pour la reproductibilit\u00e9","text":"<p>set.seed(123)</p>"},{"location":"3-Pipelines/Machine-Learning/#charger-le-jeu-de-donnees","title":"Charger le jeu de donn\u00e9es","text":"<p>data &lt;- read.csv('path/to/dataset.csv')</p>"},{"location":"3-Pipelines/Machine-Learning/#diviser-les-donnees-en-ensembles-dentrainement-et-de-test","title":"Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test","text":"<p>train_index &lt;- sample(1:nrow(data), size=0.8*nrow(data)) train_data &lt;- data[train_index,] test_data &lt;- data[-train_index,]</p>"},{"location":"3-Pipelines/Machine-Learning/#former-le-modele-de-regression-lineaire","title":"Former le mod\u00e8le de r\u00e9gression lin\u00e9aire","text":"<p>lm_model &lt;- lm(target_variable ~ ., data=train_data)</p>"},{"location":"3-Pipelines/Machine-Learning/#faire-des-predictions-sur-lensemble-de-test","title":"Faire des pr\u00e9dictions sur l'ensemble de test","text":"<p>y_pred &lt;- predict(lm_model, newdata=test_data[,-which(names(test_data)=='target_variable')])</p>"},{"location":"3-Pipelines/Machine-Learning/#evaluer-les-performances-du-modele","title":"\u00c9valuer les performances du mod\u00e8le","text":"<p>mse &lt;- mean((y_pred - test_data$target_variable)^2) rmse &lt;- sqrt(mse) print(paste('Root Mean Squared Error:', rmse))  ```</p>"},{"location":"3-Pipelines/Machine-Learning/#machine-a-vecteurs-de-support-svm","title":"Machine \u00e0 vecteurs de support (SVM)","text":"<p>SVM</p> <p>$$  \\underset{\\mathbf{w},b,\\boldsymbol{\\xi}}{\\operatorname{minimize}} \\hspace{0.2cm} \\frac{1}{2} ||\\mathbf{w}||^2 + C \\sum_{i=1}^{N} \\xi_i  $$</p> <p>$$  \\text{o\u00f9} \\hspace{0.2cm} y_i(\\mathbf{w}^T\\mathbf{x}_i + b) \\geq 1-\\xi_i \\quad \\text{and} \\quad \\hspace{0.2cm} \\xi_i \\geq 0 \\hspace{0.2cm} \\forall i \\in {1,2,...,N}  $$</p> <p>Dans cette formule, nous utilisons la formulation SVM standard o\u00f9 \\(\\mathbf{w}\\) est le vecteur de poids, \\(b\\) est le terme de biais et \\(\\boldsymbol{\\xi}\\) est le vecteur variable d'\u00e9cart. L'objectif est de minimiser la norme L2 du vecteur de poids \\(\\mathbf{w}\\), sous la contrainte que tous les exemples d'apprentissage sont class\u00e9s correctement avec une marge d'au moins 1, plus une tol\u00e9rance pour certaines violations de marge contr\u00f4l\u00e9es par le param\u00e8tre de r\u00e9gularisation \\(C\\). La variable cible \\(y_i\\) prend les valeurs 1 ou -1, repr\u00e9sentant les deux classes du probl\u00e8me de classification binaire, et \\(\\mathbf{x}_i\\) est le vecteur de caract\u00e9ristiques pour le \\(i\\)i\u00e8me exemple d'entra\u00eenement.</p> <p>Une machine \u00e0 vecteurs de support (SVM) est un algorithme d'apprentissage automatique supervis\u00e9 qui peut \u00eatre utilis\u00e9 pour la classification, la r\u00e9gression et la d\u00e9tection des valeurs aberrantes. C'est un algorithme populaire dans le domaine de l'apprentissage automatique, en particulier pour r\u00e9soudre les probl\u00e8mes de classification.</p> <p>L'id\u00e9e de base derri\u00e8re SVM est de trouver un hyperplan qui s\u00e9pare au mieux les donn\u00e9es d'entr\u00e9e en diff\u00e9rentes classes. Dans un probl\u00e8me de classification \u00e0 deux classes, l'hyperplan est une ligne qui s\u00e9pare les points de donn\u00e9es d'une classe des points de donn\u00e9es de l'autre classe. SVM essaie de trouver l'hyperplan qui maximise la marge entre les deux classes, o\u00f9 la marge est la distance entre l'hyperplan et les points de donn\u00e9es les plus proches de chaque classe.</p>"},{"location":"3-Pipelines/Machine-Learning/#exemple-de-code_1","title":"Exemple de code","text":"PythonR svm.py<pre><code>#!/usr/bin/env python\n# Charger les biblioth\u00e8ques requises\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n# Charger le jeu de donn\u00e9es\ndata = pd.read_csv('path/to/dataset.csv')\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nX_train, X_test, y_train, y_test = train_test_split(data.drop('target_variable', axis=1), data['target_variable'], test_size=0.2)\n# Former le mod\u00e8le SVM\nsvm_model = SVC(kernel='linear', C=1.0, random_state=42)\nsvm_model.fit(X_train, y_train)\n# Faire des pr\u00e9dictions sur l'ensemble de test\ny_pred = svm_model.predict(X_test)\n# \u00c9valuer les performances du mod\u00e8le\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)\n</code></pre> svm.r<pre><code>#!/usr/bin/env Rscript\n# Charger les biblioth\u00e8ques requises\nlibrary(e1071)\n# Charger le jeu de donn\u00e9es\ndata &lt;- read.csv('path/to/dataset.csv')\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nset.seed(123)\ntrain_index &lt;- sample(1:nrow(data), size=0.8*nrow(data))\ntrain_data &lt;- data[train_index,]\ntest_data &lt;- data[-train_index,]\n# Former le mod\u00e8le SVM\nsvm_model &lt;- svm(target_variable ~ ., data=train_data, kernel='linear', cost=1)\n# Faire des pr\u00e9dictions sur l'ensemble de test\ny_pred &lt;- predict(svm_model, newdata=test_data[,-which(names(test_data)=='target_variable')])\n# \u00c9valuer les performances du mod\u00e8le\naccuracy &lt;- mean(y_pred == test_data$target_variable)\nprint(paste('Accuracy:', accuracy))\n</code></pre>"},{"location":"3-Pipelines/Machine-Learning/#foret-aleatoire","title":"For\u00eat al\u00e9atoire","text":"<p>For\u00eat al\u00e9atoire</p> <p>$$  \\hat{y} = \\frac{1}{T} \\sum_{t=1}^{T} f_t(\\mathbf{x}),  $$</p> <p>o\u00f9 \\(\\hat{y}\\) est la sortie pr\u00e9dite, \\(f_t(\\mathbf{x})\\) est la pr\u00e9diction du \\(t\\)i\u00e8me arbre de la for\u00eat pour l'entr\u00e9e \\(\\mathbf{x}\\), et $T $ est le nombre d'arbres dans la for\u00eat.</p> <p>Les for\u00eats al\u00e9atoires sont une m\u00e9thode d'apprentissage d'ensemble qui peut \u00eatre utilis\u00e9e pour les probl\u00e8mes de classification et de r\u00e9gression. Ils sont souvent utilis\u00e9s pour leur capacit\u00e9 \u00e0 g\u00e9rer des ensembles de donn\u00e9es dimensionnelles \u00e0 haute variation et des relations non lin\u00e9aires entre les entit\u00e9s et les cibles.</p> <p>Chaque arbre est entra\u00een\u00e9 sur un sous-ensemble amorc\u00e9 des donn\u00e9es d'entra\u00eenement d'origine, et \u00e0 chaque division, un sous-ensemble al\u00e9atoire de caract\u00e9ristiques est pris en compte pour d\u00e9terminer la division. La pr\u00e9diction finale est obtenue en faisant la moyenne des pr\u00e9dictions de tous les arbres de la for\u00eat.</p>"},{"location":"3-Pipelines/Machine-Learning/#exemple-de-code_2","title":"Exemple de code","text":"PythonR random_forest.py<pre><code>#!/usr/bin/env python\n# Charger les biblioth\u00e8ques requises\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n# Charger le jeu de donn\u00e9es\ndata = pd.read_csv('path/to/dataset.csv')\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nX_train, X_test, y_train, y_test = train_test_split(data.drop('target_variable', axis=1), data['target_variable'], test_size=0.2)\n# Former le mod\u00e8le de for\u00eat al\u00e9atoire\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n# Faire des pr\u00e9dictions sur l'ensemble de test\ny_pred = rf_model.predict(X_test)\n# \u00c9valuer les performances du mod\u00e8le\nmse = mean_squared_error(y_test, y_pred)\nrmse = mse ** 0.5\nprint('Root Mean Squared Error:', rmse)\n</code></pre> random_forest.r<pre><code>#!/usr/bin/env Rscript\n# Charger les biblioth\u00e8ques requises\nlibrary(randomForest)\n# Charger le jeu de donn\u00e9es\ndata &lt;- read.csv('path/to/dataset.csv')\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nset.seed(123)\ntrain_index &lt;- sample(1:nrow(data), size=0.8*nrow(data))\ntrain_data &lt;- data[train_index,]\ntest_data &lt;- data[-train_index,]\n# Former le mod\u00e8le de for\u00eat al\u00e9atoire\nrf_model &lt;- randomForest(target_variable ~ ., data=train_data, ntree=100, importance=TRUE)\n# Faire des pr\u00e9dictions sur l'ensemble de test\ny_pred &lt;- predict(rf_model, newdata=test_data[,-which(names(test_data)=='target_variable')])\n# \u00c9valuer les performances du mod\u00e8le\nmse &lt;- mean((y_pred - test_data$target_variable)^2)\nrmse &lt;- sqrt(mse)\nprint(paste('Root Mean Squared Error:', rmse))\n</code></pre>"},{"location":"3-Pipelines/Machine-Learning/#lapprentissage-en-profondeur","title":"L'apprentissage en profondeur","text":"<p>Apprentissage en profondeur</p> <p>$$  \\hat{y} = f(\\mathbf{W}L f(\\mathbf{W} f(\\dots f(\\mathbf{W}1\\mathbf{x}+\\mathbf{b} _1)\\dots)+\\mathbf{b})+\\mathbf{b}_L)  $$</p> <p>o\u00f9 \\(\\mathbf{x}\\) est le vecteur d'entr\u00e9e, \\(\\mathbf{W}_i\\) et \\(\\mathbf{b}_i\\) sont respectivement la matrice de pond\u00e9ration et le vecteur de biais pour la \\(i\\)i\u00e8me couche, et $ f$ est la fonction d'activation.</p> <p>Cette formule repr\u00e9sente un r\u00e9seau de neurones \u00e0 anticipation avec des couches \\(L\\), o\u00f9 chaque couche applique une transformation lin\u00e9aire \u00e0 la sortie de la couche pr\u00e9c\u00e9dente, suivie d'une fonction d'activation non lin\u00e9aire. La sortie de la couche finale, \\(\\hat{y}\\), repr\u00e9sente la sortie pr\u00e9dite du r\u00e9seau de neurones pour l'entr\u00e9e donn\u00e9e \\(\\mathbf{x}\\).</p> <p>L'apprentissage en profondeur est un sous-ensemble de l'apprentissage automatique qui implique la formation de r\u00e9seaux de neurones avec de nombreuses couches de n\u0153uds interconnect\u00e9s. Cette approche peut g\u00e9rer des ensembles de donn\u00e9es volumineux et complexes et est utilis\u00e9e dans un large \u00e9ventail d'applications, notamment la reconnaissance d'images, le traitement du langage naturel et la reconnaissance vocale. Le processus de formation consiste \u00e0 alimenter le r\u00e9seau de neurones avec un grand ensemble de donn\u00e9es et \u00e0 ajuster les poids des connexions entre les n\u0153uds pour minimiser l'erreur entre les sorties pr\u00e9dites et les sorties r\u00e9elles. Gr\u00e2ce \u00e0 des it\u00e9rations r\u00e9p\u00e9t\u00e9es, le r\u00e9seau de neurones peut apprendre \u00e0 reconna\u00eetre des mod\u00e8les dans les donn\u00e9es et \u00e0 faire des pr\u00e9dictions pr\u00e9cises sur de nouvelles donn\u00e9es.</p>"},{"location":"3-Pipelines/Machine-Learning/#exemple-de-code_3","title":"Exemple de code","text":"PythonR deep_learning.py<pre><code>#!/usr/bin/env python\n# Charger les biblioth\u00e8ques requises\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n# Charger le jeu de donn\u00e9es\ndata = pd.read_csv('path/to/dataset.csv')\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nX_train, X_test, y_train, y_test = train_test_split(data.drop('target_variable', axis=1), data['target_variable'], test_size=0.2)\n# Standardiser les caract\u00e9ristiques d'entr\u00e9e\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# D\u00e9finir le mod\u00e8le de deep learning\nmodel = keras.Sequential([\nkeras.layers.Dense(64, activation='relu', input_shape=[X_train_scaled.shape[1]]),\nkeras.layers.Dropout(0.2),\nkeras.layers.Dense(1, activation='sigmoid')\n])\n# Compiler le mod\u00e8le\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# Former le mod\u00e8le\nhistory = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1)\n# \u00c9valuer les performances du mod\u00e8le\ny_pred = model.predict_classes(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)\n</code></pre> deep_learning.r<pre><code>#!/usr/bin/env Rscript\n# Charger les biblioth\u00e8ques requises\nlibrary(keras)\nlibrary(tensorflow)\n# Charger le jeu de donn\u00e9es\ndata &lt;- iris\nx &lt;- as.matrix(data[, 1:4])\ny &lt;- to_categorical(as.numeric(data[, 5]) - 1)\n# Diviser les donn\u00e9es en ensembles d'entra\u00eenement et de test\nset.seed(123)\ntrain_index &lt;- sample(1:nrow(data), size=0.8*nrow(data))\nx_train &lt;- x[train_index,]\ny_train &lt;- y[train_index,]\nx_test &lt;- x[-train_index,]\ny_test &lt;- y[-train_index,]\n# D\u00e9finir l'architecture du r\u00e9seau neuronal\nmodel &lt;- keras_model_sequential() %&gt;%\nlayer_dense(units = 8, input_shape = c(4)) %&gt;%\nlayer_activation('relu') %&gt;%\nlayer_dense(units = 3) %&gt;%\nlayer_activation('softmax')\n# Compiler le mod\u00e8le\nmodel %&gt;% compile(\nloss = 'categorical_crossentropy',\noptimizer = 'adam',\nmetrics = c('accuracy')\n)\n# Former le mod\u00e8le\nhistory &lt;- model %&gt;% fit(\nx_train, y_train,\nepochs = 50,\nbatch_size = 10,\nvalidation_split = 0.2,\nverbose = 0\n)\n# \u00c9valuer les performances du mod\u00e8le\nmetrics &lt;- model %&gt;% evaluate(x_test, y_test)\nprint(paste('Test Loss:', metrics[1]))\nprint(paste('Test Accuracy:', metrics[2]))\n# Tracez la pr\u00e9cision de la formation et de la validation dans le temps\nplot(history$metrics$accuracy, type='l', col='blue', ylim=c(0,1), ylab='Accuracy', xlab='Epoch')\nlines(history$metrics$val_accuracy, type='l', col='red')\nlegend('bottomright', legend=c('Training', 'Validation'), col=c('blue', 'red'), lty=1)\n</code></pre>"},{"location":"3-Pipelines/PaaS/","title":"Int\u00e9grer avec des plateformes comme Databricks et AzureML","text":"<p>La plateforme AAW est construite autour de l'id\u00e9e d'int\u00e9grations, et nous pouvons donc s'int\u00e9grer avec de nombreuses offres de \"plateforme en tant que service\" (PaaS), telles que Azure ML et Databricks.</p> <p>Voir quelques exemples dans notre D\u00e9p\u00f4t Github \"MLOps\".</p> <p></p>"},{"location":"3-Pipelines/Serving/","title":"Service de mod\u00e8le avec Seldon Core et KFServing","text":"<p>\u2692 Cette page est en construction \u2692</p> <p>La personne qui \u00e9crit cette entr\u00e9e n'en sait pas assez sur cette fonctionnalit\u00e9 pour \u00e9crire \u00e0 son sujet, mais vous pouvez demander sur notre canal en Slack.</p>"},{"location":"3-Pipelines/Serving/#sans-serveur-avec-knative","title":"Sans-serveur avec KNative","text":"<p>Kubernetes et [KNative] (https://knative.dev/) permettent \u00e0 vos services de monter ou descendre en puissance \u00e0 la demande. Cela vous permet de cr\u00e9er des API pour servir des mod\u00e8les d'apprentissage automatique, sans avoir besoin de g\u00e9rer l'\u00e9quilibrage de charge ou la mont\u00e9e en puissance. La plateforme peut g\u00e9rer toute votre mise \u00e0 l'\u00e9chelle pour vous, afin que vous puissiez vous concentrer sur la logique du programme.</p> <p>\u2692 Cette page est en construction \u2692</p> <p>La personne qui r\u00e9dige cette entr\u00e9e ne conna\u00eet pas suffisamment cette fonctionnalit\u00e9 pour \u00e9crire \u00e0 son sujet, mais vous pouvez demander sur notre canal en Slack.</p>"},{"location":"4-Collaboration/Aper%C3%A7u/","title":"Aper\u00e7u","text":"<p>Il existe de nombreuses fa\u00e7ons de collaborer sur la plateforme. Selon votre situation,ce qu vous voulez partager et le nombre de personnes que vous souhaitez partager avec. Les sc\u00e9narios se d\u00e9composent en gros en ce que vous voulez partager (Donn\u00e9es, Code, ou Environnements de calcul (e.g.: Partager les m\u00eames machines virtuelles)) et avec qui vous voulez le partager (Personne, Mon \u00e9quipe, ou Tout le monde). Cela conduit au tableau d'options suivant:</p> Priv\u00e9e \u00c9quipe StatCan Code GitLab/GitHub ou un dossier personnel GitLab/GitHub or dossier d'\u00e9quipe GitLab/GitHub Donn\u00e9es Dossier personnel ou compartiment Dossier d'\u00e9quipe ou compartiment , ou espace de noms partag\u00e9 Compartiment partag\u00e9 Calcul Espace de nom personnel Espace de noms partag\u00e9 N/A Quelle est la diff\u00e9rence entre un compartiment et un dossier? <p>Les compartiments sont comme le stockage sur r\u00e9seau. Consulter  pr\u00e9sentation du stockage pour plus de d\u00e9tails sur les diff\u00e9rences entre ces deux options.</p> <p>Choisir la meilleure fa\u00e7on de partager le code, les donn\u00e9es et le calcul implique des facteurs, mais vous pouvez g\u00e9n\u00e9ralement m\u00e9langer et assortir (partager le code avec votre \u00e9quipe via github, mais stockez vos donn\u00e9es en priv\u00e9 dans un compartiment personnel). Ces cas sont d\u00e9crits plus en d\u00e9tail dans les sections ci-dessous</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#partager-le-code-entre-les-membres-de-lequipe","title":"Partager le code entre les membres de l'\u00e9quipe","text":"<p>Dans la plupart des cas, il est plus facile de partager du code en utilisant GitHub ou GitLab. L'avantage du partage avec GitHub ou GitLab est que cela fonctionne avec les utilisateurs \u00e0 travers les espaces de noms, et conserver le code dans github est un excellent moyen de g\u00e9rer de grands projets logiciels.</p> N'oubliez pas d'inclure une licence ! <p>Si votre code est public, n'oubliez pas de respecter les directives de l'\u00e9quipe d'innovation et d'utiliser une licence appropri\u00e9e si votre travail est effectu\u00e9 pour Statistique Canada.</p> <p>Si vous devez partager du code sans le publier sur un r\u00e9f\u00e9rentiel, partager un espace de nom) pourrait aussi fonctionner.</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#partager-le-calcul-espace-de-nom-dans-kubeflow","title":"Partager le calcul (espace de nom) dans Kubeflow","text":"<p>!!! danger \"Partager un espace de nom signifie que vous partagez toutes les choses     dans l'espace de nom\".     Kubeflow ne prend pas en charge le partage granulaire d'une ressource (un bloc-notes, un compartiment MinIO, etc.), mais plut\u00f4t le partage de tous ressources. Si vous souhaitez partager un serveur Jupyter Carnet note avec quelqu'un, vous devez partager l'int\u00e9gralit\u00e9 de votre espace de nom et ils auront acc\u00e8s \u00e0 toutes les autres ressources (compartiment MinIO, etc.).</p> <p>Dans Kubeflow, chaque utilisateur dispose d'un espace de nom qui contient son travail (son serveur de Carnets notes, pipelines, disques, etc.). Votre espace de nom vous appartient, mais peut \u00eatre partag\u00e9 si vous voulez collaborer avec d'autres. Vous pouvez aussi  Demander un Espace de nom (soit pour vous-m\u00eame, soit pour partager avec une \u00e9quipe). Une option de collaboration consiste \u00e0 partager des espaces de noms avec les autres.</p> <p>L'avantage de partager un espace de nom Kubeflow est qu'il vous permet, ainsi qu'\u00e0 vos coll\u00e8gues partagent l'environnement de calcul et les compartiments MinIO associ\u00e9s au espace de nom. Cela en fait un moyen tr\u00e8s simple et libre de partager.</p> Demander de l'aide en production <p>Le personnel d'assistance d'Espace de travail d'analyse avanc\u00e9e se fera un plaisir de vous aider avec les cas d'utilisation orient\u00e9s vers la production, et nous pouvons probablement vous faire gagner beaucoup de temps. Ne soyez pas timide Demander pour l'aide!</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#partager-des-donnees","title":"Partager des donn\u00e9es","text":"<p>Une fois que vous avez un espace de nom partag\u00e9, vous avez deux approches de stockage partag\u00e9</p> Possibilit\u00e9 de stockage Avantages Serveurs/espaces de travail Jupyter partag\u00e9s Plus adapt\u00e9 aux petits fichiers, aux cahiers et aux petites exp\u00e9riences. Compartiments partag\u00e9s( consultez Stockage) Mieux adapt\u00e9 pour une utilisation dans les pipelines, les API et pour les fichiers volumineux. <p>Pour en savoir plus sur la technologie qui les sous-tend, consultez le Stockage.</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#partager-avec-statcan","title":"Partager avec StatCan","text":"<p>En plus des compartiments priv\u00e9s ou des compartiments priv\u00e9s partag\u00e9s par l'\u00e9quipe, vous pouvez \u00e9galement placez vos fichiers dans le stockage partag\u00e9. Dans toutes les options de stockage de compartiment (<code>minimal</code>, <code>premium</code>, <code>pachyderm</code>), vous disposez d'un compartiment priv\u00e9, et d'un dossier \u00e0 l'int\u00e9rieur du compartiment \u00ab partag\u00e9 \u00bb. Jetez un \u0153il, par exemple, au lien ci-dessous :</p> <ul> <li><code>shared/blair-drummond/</code></li> </ul> <p>Tout utilisateur connect\u00e9 peut voir ces fichiers et les lire librement.</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#partage-avec-le-monde","title":"Partage avec le monde","text":"<p>Renseignez-vous sur celui-ci dans notre cha\u00eene Slack. L\u00e0 il existe de nombreuses fa\u00e7ons de le faire du c\u00f4t\u00e9 informatique, mais il est important que cela aille par des processus appropri\u00e9s, de sorte que cela ne se fait pas de mani\u00e8re \u00ab libre-service \u00bb que d'autres sont. Cela dit, c'est tout \u00e0 fait possible.</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#recommandation-combinez-les-tous","title":"Recommandation : Combinez-les tous","text":"<p>C'est une excellente id\u00e9e de toujours utiliser github avec des espaces de travail partag\u00e9s est un excellent moyen de combiner le partage ad hoc (via des fichiers) tout en gardant votre code organis\u00e9 et suivi</p>"},{"location":"4-Collaboration/Aper%C3%A7u/#gestion-des-contributeurs","title":"Gestion des contributeurs","text":"<p>Vous pouvez ajouter ou supprimer des personnes d'un espace de nom que vous poss\u00e9dez d\u00e9j\u00e0 via le Menu G\u00e9rer les contributeurs dans Kubeflow.</p> <p></p> <p>Maintenant, vous et vos coll\u00e8gues pouvez partager l'acc\u00e8s \u00e0 un serveur!</p> <p>Essayer le!</p>"},{"location":"4-Collaboration/Demander-EspaceDeNom/","title":"Aper\u00e7u","text":"<p>Par d\u00e9faut, tout le monde obtient son propre espace de nom personnel, <code>pr\u00e9nom-nom</code>. Si vous souhaitez collaborer avec votre \u00e9quipe, vous pouvez demander un Espace de nom \u00e0 partager.</p>"},{"location":"4-Collaboration/Demander-EspaceDeNom/#installation","title":"Installation","text":""},{"location":"4-Collaboration/Demander-EspaceDeNom/#demander-un-espace-de-nom","title":"Demander un espace de nom","text":"<p>Pour cr\u00e9er un espace de noms pour une \u00e9quipe, acc\u00e9dez au portail AAW. Cliquez sur le \u22ee menu sur la section Kubeflow du portail.</p> <p></p> <p>Entrez le nom que vous demandez et soumettez la demande. Veillez \u00e0 n'utiliser que lettres minuscules plus tirets. </p> <p>!!! avertissement \"L'espace de noms ne peut pas avoir de caract\u00e8res sp\u00e9ciaux autres que       des traits d'union\"     Le nom de l'espace de noms ne doit \u00eatre compos\u00e9 que de lettres minuscules \u00ab a-z \u00bb avec des tirets. Sinon,l'espace de noms ne sera pas cr\u00e9\u00e9.</p> <p>Vous recevrez une notification par e-mail lorsque l'espace de noms sera cr\u00e9\u00e9. Une fois l'espace de noms partag\u00e9 est cr\u00e9\u00e9, vous pouvez y acc\u00e9der comme n'importe quel autre l'espace de noms que vous avez via l'interface utilisateur de Kubeflow, comme illustr\u00e9 ci-dessous. Vous serez alors capable de partager et g\u00e9rer \u00e0 votre espace de nom.</p> <p>Pour changer d'espace de noms, jetez un \u0153il en haut de votre fen\u00eatre, juste \u00e0 droite du logo Kubeflow.</p> <p></p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/","title":"Environnement d'Analyse G\u00e9ospatiale (EAG) - Acc\u00e8s multi-plateforme","text":"Donn\u00e9es non prot\u00e9g\u00e9es uniquement, SSI bient\u00f4t disponible! <p>\u00c0 l'heure actuelle, notre serveur g\u00e9ospatial ne peut h\u00e9berger et donner acc\u00e8s qu'\u00e0 des informations statistiques non sensibles.  </p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#demarrage","title":"D\u00e9marrage","text":"<p>Conditions pr\u00e9alables</p> <ol> <li>Un projet int\u00e9gr\u00e9 avec acc\u00e8s au portail DAS EAG ArcGIS</li> <li>Un identifiant client ArcGIS Portal (cl\u00e9 API)</li> </ol> <p>Le portail ArcGIS Enterprise est accessible dans AAW ou CAE \u00e0 l'aide de l'API, \u00e0 partir de n'importe quel service qui exploite le langage de programmation Python. </p> <p>Par exemple, dans AAW et l'utilisation de Jupyter Notebooks dans l'espace, ou pour CAE l'utilisation de Databricks, DataFactory, etc.</p> <p>Le portail DAS GAE ArcGIS Enterprise est accessible directement ici</p> <p>Pour obtenir de l'aide sur l'auto-inscription en tant qu'utilisateur du portail g\u00e9ospatial DAS</p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#utilisation-de-lapi-arcgis-pour-python","title":"Utilisation de l'API ArcGIS pour Python","text":""},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#connexion-a-arcgis-enterprise-portal-a-laide-de-lapi-arcgis","title":"Connexion \u00e0 ArcGIS Enterprise Portal \u00e0 l'aide de l'API ArcGIS","text":"<ol> <li> <p>Installez les packages\u00a0:</p> <pre><code>conda install -c esri arcgis\n</code></pre> <p>ou utilisez Artifactory</p> <pre><code>conda install -c https://jfrog.aaw.cloud.statcan.ca/artifactory/api/conda/esri-remote arcgis\n</code></pre> </li> <li> <p>Importez les librairies n\u00e9cessaires dont vous aurez besoin dans le Notebook.     <pre><code>from arcgis.gis import GIS\nfrom arcgis.gis import Item\n</code></pre></p> </li> <li> <p>Acc\u00e9der au portail    Votre groupe de projet recevra un identifiant client lors de l'int\u00e9gration. Collez l'ID client entre les guillemets<code>client_id='######'</code>. </p> <pre><code>gis = GIS(\"https://geoanalytics.cloud.statcan.ca/portal\", client_id=' ')\nprint(\"Successfully logged in as: \" + gis.properties.user.username)\n</code></pre> </li> <li> <ul> <li>La sortie vous redirigera vers un portail de connexion.</li> <li>Utilisez l'option de connexion Azure de StatCan et votre identifiant Cloud</li> <li>Apr\u00e8s une connexion r\u00e9ussie, vous recevrez un code pour vous connecter en utilisant SAML.</li> <li> <p>Collez ce code dans la sortie.</p> <p></p> </li> </ul> </li> </ol>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#afficher-les-informations-utilisateur","title":"Afficher les informations utilisateur","text":"<p>En utilisant la fonction \"me\", nous pouvons afficher diverses informations sur l'utilisateur connect\u00e9. <pre><code>me = gis.users.me\nusername = me.username\ndescription = me.description\ndisplay(me)\n</code></pre></p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#rechercher-du-contenu","title":"Rechercher du contenu","text":"<p>Recherchez le contenu que vous avez h\u00e9berg\u00e9 sur le portail g\u00e9o DAaaS. En utilisant la fonction \"me\", nous pouvons rechercher tout le contenu h\u00e9berg\u00e9 sur le compte. Il existe plusieurs fa\u00e7ons de rechercher du contenu. Deux m\u00e9thodes diff\u00e9rentes sont d\u00e9crites ci-dessous.</p> <p>Recherchez tous vos \u00e9l\u00e9ments h\u00e9berg\u00e9s dans le portail g\u00e9ographique DAaaS. <pre><code>my_content = me.items()\nmy_content\n</code></pre> Recherchez du contenu sp\u00e9cifique que vous poss\u00e9dez dans le portail g\u00e9ographique DAaaS.</p> <p>Ceci est similaire \u00e0 l'exemple ci-dessus, mais si vous connaissez le titre de la couche que vous souhaitez utiliser, vous pouvez l'enregistrer en tant que fonction. <pre><code>my_items = me.items()\nfor items in my_items:\nprint(items.title, \" | \", items.type)\nif items.title == \"Flood in Sorel-Tracy\":\nflood_item = items\nelse:\ncontinue\nprint(flood_item)\n</code></pre></p> <p>Recherchez tout le contenu auquel vous avez acc\u00e8s, pas seulement le v\u00f4tre.</p> <pre><code>flood_item = gis.content.search(\"tags: flood\", item_type =\"Feature Service\")\nflood_item\n</code></pre>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#obtenir-du-contenu","title":"Obtenir du contenu","text":"<p>Nous devons obtenir l'\u00e9l\u00e9ment du portail g\u00e9ographique DAaaS afin de l'utiliser dans le bloc-notes Jupyter. Cela se fait en fournissant le num\u00e9ro d'identification unique de l'article que vous souhaitez utiliser. Trois exemples sont d\u00e9crits ci-dessous, tous acc\u00e9dant \u00e0 la m\u00eame couche. <pre><code>item1 = gis.content.get(my_content[5].id) #from searching your content above\ndisplay(item1)\nitem2 = gis.content.get(flood_item.id) #from example above -searching for specific content\ndisplay(item2)\nitem3 = gis.content.get('edebfe03764b497f90cda5f0bfe727e2') #the actual content id number\ndisplay(item3)\n</code></pre></p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#effectuer-une-analyse","title":"Effectuer une analyse","text":"<p>Une fois les couches import\u00e9es dans le bloc-notes Jupyter, nous sommes en mesure d'effectuer des types d'analyse similaires \u00e0 ceux que vous vous attendriez \u00e0 trouver dans un logiciel SIG tel qu'ArcGIS. Il existe de nombreux modules contenant de nombreux sous-modules qui peuvent effectuer plusieurs types d'analyses. </p> <p>\u00c0 l'aide du module arcgis.features, importez le sous-module use_proximity <code>from arcgis.features import use_proximity</code>. Ce sous-module nous permet de <code>.create_buffers</code> - des zones \u00e0 \u00e9gale distance des entit\u00e9s. Ici, nous sp\u00e9cifions la couche que nous voulons utiliser, la distance, les unit\u00e9s et le nom de sortie (vous pouvez \u00e9galement sp\u00e9cifier d'autres caract\u00e9ristiques telles que le champ, le type d'anneau, le type de fin et autres). En sp\u00e9cifiant un nom de sortie, apr\u00e8s avoir ex\u00e9cut\u00e9 la commande buffer, une nouvelle couche sera automatiquement t\u00e9l\u00e9charg\u00e9e dans le portail DAaaS GEO contenant la nouvelle fonctionnalit\u00e9 que vous venez de cr\u00e9er. </p> <pre><code>buffer_lyr = use_proximity.create_buffers(item1, distances=[1], \nunits = \"Kilometers\", \noutput_name='item1_buffer')\ndisplay(item1_buffer)\n</code></pre> <p>Certains utilisateurs pr\u00e9f\u00e8rent travailler avec des packages Open Source. La traduction d'ArcGIS vers Spatial Dataframes est simple. <pre><code># create a Spatially Enabled DataFrame object\nsdf = pd.DataFrame.spatial.from_layer(feature_layer)\n</code></pre></p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#mettre-a-jour-les-elements","title":"Mettre \u00e0 jour les \u00e9l\u00e9ments","text":"<p>En obtenant l'\u00e9l\u00e9ment comme nous l'avons fait similaire \u00e0 l'exemple ci-dessus, nous pouvons utiliser la fonction <code>.update</code> pour mettre \u00e0 jour l'\u00e9l\u00e9ment existant dans le portail DAaaS GEO. Nous pouvons mettre \u00e0 jour les propri\u00e9t\u00e9s, les donn\u00e9es, les vignettes et les m\u00e9tadonn\u00e9es des \u00e9l\u00e9ments. <pre><code>item1_buffer = gis.content.get('c60c7e57bdb846dnbd7c8226c80414d2')\nitem1_buffer.update(item_properties={'title': 'Enter Title'\n'tags': 'tag1, tag2, tag3, tag4',\n'description': 'Enter description of item'}\n</code></pre></p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#visualisez-vos-donnees-sur-une-carte-interactive","title":"Visualisez vos donn\u00e9es sur une carte interactive","text":"<p>Exemple\u00a0: Librairie MatplotLib Dans le code ci-dessous, nous cr\u00e9ons un objet ax, qui est un trac\u00e9 de style carte. Nous tra\u00e7ons ensuite notre colonne de changement de donn\u00e9es (\"Population Change\") sur les axes <pre><code>import matplotlib.pyplot as plt\nax = sdf.boundary.plot(figsize=(10, 5))\nshape.plot(ax=ax, column='Population Change', legend=True)\nplt.show()\n</code></pre></p> <p>Exemple\u00a0: librairie ipyleaflet Dans cet exemple, nous utiliserons la librairie 'ipyleaflet' pour cr\u00e9er une carte interactive. Cette carte sera centr\u00e9e autour de Toronto, ON. Les donn\u00e9es utilis\u00e9es seront d\u00e9crites ci-dessous. Commencez par coller <code>conda install -c conda-forge ipyleaflet</code> vous permettant d'installer les librairies ipyleaflet dans l'environnement Python.  Import the necessary libraries. <pre><code>import ipyleaflet \nfrom ipyleaflet import *\n</code></pre> Maintenant que nous avons import\u00e9 le module ipyleaflet, nous pouvons cr\u00e9er une carte simple en sp\u00e9cifiant la latitude et la longitude de l'emplacement que nous voulons, le niveau de zoom et le fond de carte (plus de fonds de carte). Des contr\u00f4les suppl\u00e9mentaires ont \u00e9t\u00e9 ajout\u00e9s tels que les calques et l'\u00e9chelle. <pre><code>toronto_map = Map(center=[43.69, -79.35], zoom=11, basemap=basemaps.Esri.WorldStreetMap)\ntoronto_map.add_control(LayersControl(position='topright'))\ntoronto_map.add_control(ScaleControl(position='bottomleft'))\ntoronto_map\n</code></pre> </p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#en-savoir-plus-sur-lapi-arcgis-pour-python","title":"En savoir plus sur l'API ArcGIS pour Python","text":"<p>La documentation compl\u00e8te de l'API ArcGIS peut \u00eatre trouv\u00e9e ici</p>"},{"location":"4-Collaboration/Environnement-Analyse-Geospatiale/#en-savoir-plus-sur-lenvironnement-analytique-geospatial-gae-et-les-services-das","title":"En savoir plus sur l'environnement analytique g\u00e9ospatial (GAE) et les services DAS","text":"<p>Guide d'aide GAE</p>"},{"location":"5-Stockage/Aper%C3%A7u/","title":"Stockage","text":"<p>La plateforme propose plusieurs types de stockage :</p> <ul> <li>Disque (\u00e9galement appel\u00e9 Volumes sur l'\u00e9cran de cr\u00e9ation de serveur de   blocs-note)</li> <li>Compartiment (stockage \"Blob\" ou S3, fourni via MinIO)</li> <li>Data Lakes (\u00e0 venir)</li> </ul> <p>Selon votre cas d'utilisation, le disque ou le compartiment peut \u00eatre le plus appropri\u00e9 :</p> Type Utilisateurs simultan\u00e9s Vitesse Taille totale Partageable avec d'autres utilisateurs Disque Une machine/serveur de bloc-notes \u00e0 la fois Le plus rapide (d\u00e9bit et latence) &lt;=512GB total par stockage Non Compartiment (via MinIO) Acc\u00e8s simultan\u00e9 depuis plusieurs machines/serveurs d'ordinateurs portables en m\u00eame temps Fast-ish ((T\u00e9l\u00e9chargement rapide, t\u00e9l\u00e9chargement modeste, latence modeste) Infini (dans la limite du raisonnable) [Oui] Si vous ne savez pas lequel choisir, ne vous en faites pas <p>Ce sont des lignes directrices, pas une science exacte - choisissez ce qui sonne le mieux maintenant et ex\u00e9cutez-le. Le meilleur choix pour une utilisation compliqu\u00e9e n'est pas \u00e9vident et n\u00e9cessite souvent une exp\u00e9rience pratique, donc essayer quelque chose vous aidera. Dans la plupart des situations, les deux options fonctionnent bien m\u00eame si elles ne sont pas parfaites, et n'oubliez pas que les donn\u00e9es peuvent toujours \u00eatre copi\u00e9es plus tard si vous changez d'avis.</p>"},{"location":"5-Stockage/Disque/","title":"Aper\u00e7u","text":"<p>Les disques sont les syst\u00e8mes de fichiers familiers de type disque dur auxquels vous \u00eates habitu\u00e9, fournis \u00e0 vous des disques SSD rapides !</p>"},{"location":"5-Stockage/Disque/#installation","title":"Installation","text":"<p>Lors de la cr\u00e9ation de votre serveur bloc-notes, vous demandez des disques en ajoutant des volumes de donn\u00e9es \u00e0 votre serveur de bloc-notes (illustr\u00e9 ci-dessous, avec <code>Type = New</code>). Ils sont automatiquement mont\u00e9 dans le r\u00e9pertoire (<code>Mount Point</code>) que vous choisissez, et sert de simple et moyen fiable de conserver les donn\u00e9es attach\u00e9es \u00e0 un serveur de bloc-notes .</p> <p></p> Vous payez pour tous les disques que vous poss\u00e9dez, qu'ils soient connect\u00e9s \u00e0 un serveur bloc-note ou non <p>D\u00e8s que vous cr\u00e9ez un disque, vous le payez jusqu'\u00e0 ce qu'il soit supprim\u00e9, m\u00eame si le Serveur de blocs-note  d'origine est supprim\u00e9. Voir Suppression du stockage sur disque pour plus d'informations</p>"},{"location":"5-Stockage/Disque/#une-fois-que-vous-avez-les-bases","title":"Une fois que vous avez les bases...","text":"<p>Lorsque vous supprimez votre Serveur blocs-note , vos disques ne sont pas supprim\u00e9s. Cela laisse vous r\u00e9utilisez ce m\u00eame disque (avec tout son contenu) sur un nouveau Serveur blocs-note plus tard (comme indiqu\u00e9 ci-dessus avec \u00ab Type = existant \u00bb et le \u00ab Nom \u00bb d\u00e9fini sur le volume que vous voulez r\u00e9utiliser). Si vous avez termin\u00e9 avec le disque et son contenu,  supprimez-le.</p>"},{"location":"5-Stockage/Disque/#suppression-du-stockage-sur-disque","title":"Suppression du stockage sur disque","text":"<p>Pour voir vos disques, consultez la section Volumes blocs-note de Serveur blocs-note page (ci-dessous). Vous pouvez supprimer n'importe quel disque non connect\u00e9 (ic\u00f4ne orange \u00e0 gauche) en cliquant sur l'ic\u00f4ne de la corbeille.</p> <p></p>"},{"location":"5-Stockage/Disque/#prix","title":"Prix","text":"Les mod\u00e8les de tarification sont provisoires et peuvent changer <p>Au moment de la r\u00e9daction, la tarification est couverte par la plate-forme pour les utilisateurs initiaux. Ce guide explique comment les choses devraient \u00eatre tarif\u00e9es \u00e0 l'avenir, mais cela peut changer.</p> <p>Lors du montage d'un disque, vous obtenez un Disque manag\u00e9 Azure. La tarification Disques g\u00e9r\u00e9s SSD Premium indique le co\u00fbt par disque en fonction de la taille. Notez que vous payez pour la taille de disque demand\u00e9e, et non pour la quantit\u00e9 d'espace que vous utilisent actuellement.</p> Conseils pour minimiser les co\u00fbts <p>Comme les disques peuvent \u00eatre attach\u00e9s \u00e0 un Serveur blocs-note  et r\u00e9utilis\u00e9s, un mod\u00e8le d'utilisation typique pourrait \u00eatre :</p> <ul> <li>\u00c0 9h, cr\u00e9ez un Serveur blocs-note  (demandez 2CPU/8GB RAM et un 32GB attach\u00e9   disque)</li> <li>Travaillez tout au long de la journ\u00e9e, en enregistrant les r\u00e9sultats sur le disque attach\u00e9</li> <li>\u00c0 17h, \u00e9teignez votre Serveur blocs-note  pour \u00e9viter de le payer du jour au lendemain</li> <li>REMARQUE : Le disque attach\u00e9  n'est pas d\u00e9truit  par cette action</li> <li>\u00c0 9 heures du matin le lendemain, cr\u00e9ez un nouveau serveur blocs-note et  joignez     votre disque</li> <li>Continuez votre travail...</li> </ul> <p>Cela prot\u00e8ge tout votre travail sans payer pour l'ordinateur lorsque vous ne l'utilisez pas</p>"},{"location":"5-Stockage/MinIo/","title":"Stockage","text":"<p>La plateforme propose diff\u00e9rents types de stockage, con\u00e7us pour diff\u00e9rents types de cas d'utilisation. Par cons\u00e9quent, cette section vous concerne, que vous soyez en train d'exp\u00e9rimenter, de cr\u00e9er des pipelines, ou d'\u00e9diter.</p> <p>En surface, il existe quelques types de stockage :</p> <ul> <li>des disques (aussi appel\u00e9s volumes)</li> <li>des compartiments (stockage S3 ou \u00ab blob \u00bb via MinIO)</li> <li>Data Lakes (\u00e0 venir)</li> </ul> <p>En fonction de votre cas d'utilisation, un disque ou compartiments peut \u00eatre le plus appropri\u00e9:</p> Type Usagers Simultan\u00e9s Vitesse Capacit\u00e9 Totale Peut \u00eatre partag\u00e9 avec d'autres usagers Disque Une machine/serveur bloc-notes \u00e0 la fois Plus rapide (d\u00e9bit et latence) &lt;=512GB total par disque Non Compartiment Acc\u00e8s simultan\u00e9 \u00e0 partir de plusieurs machines/serveurs bloc-notes en m\u00eame temps Assez rapide (t\u00e9l\u00e9chargement rapide, envoi modeste, latence modeste) Quantit\u00e9 infinie (dans une limite raisonnable) Oui <p>??? info \"Si vous n'\u00eates pas s\u00fbr de votre choix, ne vous inqui\u00e9tez pas\".     Il s'agit de lignes directrices, pas d'une science exacte - choisissez ce qui vous semble le mieux maintenant et faites-le.  Le meilleur choix pour une utilisation compliqu\u00e9e n'est pas \u00e9vident et n\u00e9cessite souvent une exp\u00e9rience pratique, donc le simple fait d'essayer quelque chose vous aidera.  Dans la plupart des situations, les deux options fonctionnent bien, m\u00eame si elles ne sont pas parfaites, et n'oubliez pas que les donn\u00e9es peuvent toujours \u00eatre copi\u00e9es ult\u00e9rieurement si vous changez d'avis.</p>"},{"location":"5-Stockage/MinIo/#disques","title":"Disques","text":"<p>Les disques sont les syst\u00e8mes de fichiers courants de type disque dur ou SSD. Vous pouvez monter les disques dans votre serveur Kubeflow, et m\u00eame si vous supprimez votre serveur, vous pouvez remonter les disques, car ils ne sont jamais d\u00e9truits par d\u00e9faut. C'est un moyen tr\u00e8s simple de stocker vos donn\u00e9es, et si vous partagez un espace de travail avec une \u00e9quipe, tous les membres peuvent utiliser le disque du m\u00eame serveur (comme un lecteur partag\u00e9).</p> <p></p> <p>C'est un moyen tr\u00e8s simple de stocker vos donn\u00e9es. Si vous partagez un espace de travail avec une \u00e9quipe, tous les membres peuvent utiliser le disque du m\u00eame serveur comme un lecteur partag\u00e9.</p>"},{"location":"5-Stockage/MinIo/#compartiments","title":"Compartiments","text":"<p>Les compartiments sont un peu plus compliqu\u00e9s, mais ils pr\u00e9sentent trois avantages :</p> <ul> <li> <p>Le stockage de grandes quantit\u00e9s de donn\u00e9es</p> <ul> <li>Les compartiments peuvent \u00eatre \u00e9normes (bien plus grands que les disques   durs), et ils sont rapides.</li> </ul> </li> </ul> <ul> <li> <p>Le partage de donn\u00e9es</p> <ul> <li>Vous pouvez partager des fichiers \u00e0 partir d'un compartiment en partageant   une URL que vous pouvez obtenir par l'interm\u00e9diaire d'une interface Web   simple. C'est une excellente fa\u00e7on de partager des donn\u00e9es avec des   personnes \u00e0 l'ext\u00e9rieur de votre espace de travail.</li> </ul> </li> </ul> <ul> <li> <p>L'acc\u00e8s \u00e0 la programmation</p> <ul> <li>Plus important encore, il est beaucoup plus facile pour les pipelines et les   navigateurs Web d'acc\u00e9der aux donn\u00e9es provenant de compartiments que d'un   disque dur. Donc, si vous voulez utiliser des pipelines, il faut d'abord les   configurer pour qu'ils fonctionnent avec un compartiment.</li> </ul> </li> </ul>"},{"location":"5-Stockage/MinIo/#stockage-en-compartiment","title":"Stockage en compartiment","text":"<p>Nous avons trois types de stockage en compartiment.</p> <p>Libre-service :</p> <ul> <li>Standard:   Stockage soutenu par des HDD. Par d\u00e9faut, utilisez cette option.</li> <li>Premium:   Utilisez cette option si vous avez besoin de vitesses de lecture / \u00e9criture   tr\u00e8s \u00e9lev\u00e9es, comme pour l'entra\u00eenement de mod\u00e8les sur de tr\u00e8s grands   ensembles de donn\u00e9es.</li> </ul> <p>Accessible au grand public :</p> <p>Public (en lecture seule)</p>"},{"location":"5-Stockage/MinIo/#libre-service","title":"Libre-service","text":"<p>Dans chacune des trois options de libre-service, vous pouvez cr\u00e9er un compartiment personnel. Pour vous connecter, il vous suffit d'utiliser votre OpenID.</p> <p></p> <p>Une fois que vous \u00eates connect\u00e9, vous pouvez cr\u00e9er un compartiment personnel selon le format <code>prenom-nom</code>.</p> <p></p> <p>Impossible de partager des fichiers avec votre OpenID</p> <p>\u00c0 cause d'un bogue dans MinIO, vous ne pouvez pas encore partager des fichiers. Nous esp\u00e9rons que cela sera bient\u00f4t r\u00e9solu. En attendant, \u00e7a fonctionnera bien si vous utilisez votre cl\u00e9 d'acc\u00e8s et votre cl\u00e9 secr\u00e8te, que vous pouvez obtenir aupr\u00e8s de Kubeflow.</p>"},{"location":"5-Stockage/MinIo/#partager","title":"Partager \u00e0 partir d'un compartiment priv\u00e9","text":"<p>Vous pouvez facilement partager des fichiers individuels. Utilisez simplement l'option \u00ab partager \u00bb pour un fichier particulier, et vous recevrez un lien que vous pourrez envoyer \u00e0 un  collaborateur.</p> <p></p>"},{"location":"5-Stockage/MinIo/#acces-a-la-programmation","title":"Acc\u00e8s \u00e0 la programmation","text":"<p>Nous travaillons actuellement \u00e0 un moyen de vous permettre d'acc\u00e9der \u00e0 votre stockage de compartiment par l'interm\u00e9diaire d'un dossier dans votre bloc-notes, mais en attendant, vous pouvez y acc\u00e9der par programme en utilisant l'outil de ligne de commande <code>mc</code>, ou par l'interm\u00e9diaire des appels d'API S3 dans R ou Python.</p> <p>Voir les exemples de blocs-notes!</p> <p>Un mod\u00e8le est fourni pour se connecter dans <code>R</code>, <code>python</code>, ou par la ligne de commande fournie dans <code>jupyter-notebooks/self-serve-storage</code>. Vous pouvez copier-coller et modifier ces exemples. Ils devraient r\u00e9pondre \u00e0 la plupart de vos besoins.</p>"},{"location":"5-Stockage/MinIo/#connexion-a-laide-de-mc","title":"Connexion \u00e0 l'aide de <code>mc</code>","text":"<p>Pour vous connecter, ex\u00e9cutez la commande suivante (remplacer <code>NOMCOMPLET=blair-drummond</code> par votre <code>nom-pr\u00e9nom</code> r\u00e9el) :</p> <pre><code>#!/bin/sh\nNOMCOMPLET=blair-drummond\n# Obtenir les justificatifs d'identit\u00e9\nsource /vault/secrets/minio-standard-tenant-1\n# Ajouter le stockage sous le pseudonyme \u00ab standard \u00bb\nmc config host add standard $MINIO_URL $MINIO_ACCESS_KEY $MINIO_SECRET_KEY\n# Cr\u00e9er un compartiment \u00e0 votre nom\n# NOTE : Vous pouvez *uniquement* cr\u00e9er des compartiments nomm\u00e9s avec votre PR\u00c9NOM-NOM.\n# Tout autre nom sera rejet\u00e9.\n# Compartiment priv\u00e9 (\"mb\" = \"cr\u00e9er compartiment\")\nmc mb standard/${NOMCOMPLET}\n# Compartiment partag\u00e9\nmc mb standard/shared/${NOMCOMPLET}\n# Voil\u00e0! Vous pouvez maintenant copier des fichiers ou des dossiers!\n[ -f test.txt ] || echo \"Ceci est un test\" &gt; test.txt\nmc cp test.txt standard/${NOMCOMPLET}/test.txt\n</code></pre> <p>Maintenant, ouvrez le document dans le navigateur MinIO. Vous y verrez votre fichier de test.</p> <p>Vous pouvez utiliser <code>mc</code> pour copier des fichiers vers/depuis le compartiment. Cette op\u00e9ration est tr\u00e8s rapide. Vous pouvez \u00e9galement utiliser <code>mc --help</code> pour voir les autres options qui s'offrent \u00e0 vous, comme <code>mc ls standard/PR\u00c9NOM-NOM/</code> pour afficher le contenu de votre compartiment.</p> Autres options de stockage <p>Pour utiliser une de nos autres options de stockage, <code>premium</code>, remplacez simplement  la valeur <code>standard</code> dans le programme ci-dessus par le type dont vous avez besoin.</p>"},{"location":"5-Stockage/MinIo/#obtenir-linformation-didentification-de-minio","title":"Obtenir l'information d'identification de MinIO","text":"<p>Pour acc\u00e9der \u00e0 vos stockage en compartiment en MinIO par programme (par exemple via l'outil de l'invite de commande <code>mc</code>, ou via Python ou R), vous avez besoin d'informations d'identification personnelles de MinIO. Les m\u00e9thodes pour obtenir celles-ci sont expliqu\u00e9es ci-dessous.</p>"},{"location":"5-Stockage/MinIo/#methode-1-utiliser-le-vault","title":"M\u00e9thode 1: Utiliser le Vault","text":"<p>Pour obtenir vos informations d'identification MinIO, vous pouvez utiliser le Vault. S\u00e9lectionnez la m\u00e9thode OIDC, laissez le R\u00f4le vide et cliquez \u00ab Sign In with OIDC Provider \u00bb.</p> <p></p> <p>Ex\u00e9cutez la commande suivante dans le terminal situ\u00e9 dans le coin \u00e0 droit:</p> <pre><code># Replacez standard avec premium pour changer le type de compartiment\nread minio_standard_tenant_1/keys/profile-votrepr\u00e9nom-votrenom\n</code></pre> <p></p>"},{"location":"5-Stockage/MinIo/#methode-2-utiliser-le-serveur","title":"M\u00e9thode 2: Utiliser le Serveur","text":"<p>D\u00e9marrez votre serveur et ex\u00e9cutez la commande suivante:</p> <pre><code>cat /vault/secrets/minio-standard-tenant-1\n\n# Output:\n# export MINIO_URL=\"http://minio.minio-standard-tenant-1 ...\"\n# export MINIO_ACCESS_KEY=\"...\"\n# export MINIO_SECRET_KEY=\"...\"\n</code></pre>"}]}